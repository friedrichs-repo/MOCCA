{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f1e5dd-99a2-4065-ae58-8b28bdaa523a",
   "metadata": {},
   "source": [
    "#### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27b1bb0a-93ee-43fe-a22a-26fe0c830211",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'../mocsy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f974531b-e417-49ff-9c59-d45f4e31a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mocsy\n",
    "from mocsy import mvars\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c27fdcfc-6816-4aa0-88f6-75e5a80d8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696a537-4cc5-4088-83da-e853a259c478",
   "metadata": {},
   "source": [
    "#### Calculate fCO2 training data with mocsy routine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce5c4036-fa74-4a51-9ed4-c0f8fde59940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_fCO2(alk, dic, tem, sal, sil, phos):\n",
    "    # input units\n",
    "    # alk in mol / kg\n",
    "    # dic in mol / kg\n",
    "    # tem in °C\n",
    "    # sal in PSU\n",
    "    # sil in mol / kg\n",
    "    # phos in mol / kg\n",
    "    n = len(alk)\n",
    "    return mvars(alk=alk,\n",
    "                     dic=dic,\n",
    "                     temp=tem,\n",
    "                     sal=sal,\n",
    "                     sil=sil,\n",
    "                     phos=phos,\n",
    "                     patm=tuple(1 for _ in range(n)),\n",
    "                     depth=tuple(5 for _ in range(n)),\n",
    "                     lat=tuple(np.nan for _ in range(n)),\n",
    "                     optcon='mol/kg',\n",
    "                     optt='Tpot',\n",
    "                     optp='db',\n",
    "                     optk1k2='l',\n",
    "                     optb='u74',\n",
    "                     optkf='pf',\n",
    "                     opts='Sprc')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "329f9dc6-8f17-41dc-9ba0-29cbcdd5c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "samples = []\n",
    "sample_size = 6000_000\n",
    "for i in range(sample_size):\n",
    "    # alk between 1700e-6 and 2700e-6 mol kg-1\n",
    "    alk = np.random.uniform(low=1700e-6, high=2700e-6)\n",
    "    # dic between 1700e-6 mol kg-1 and alk\n",
    "    dic = np.random.uniform(low=1700e-6, high=alk)\n",
    "    # tem between 2 and 35 °C\n",
    "    tem = np.random.uniform(low=2, high=35)\n",
    "    # sal between 19 and 43 PSU\n",
    "    sal = np.random.uniform(low=19, high=43)\n",
    "    # sil between 0 and 134 mumol kg-1\n",
    "    sil = np.random.uniform(low=0, high=134e-6)\n",
    "    # phos between 0 and 4 mumol kg-1\n",
    "    phos = np.random.uniform(low=0, high=4e-6)\n",
    "    sample = (alk, dic, tem, sal, sil, phos)\n",
    "    samples.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33a458ef-b191-4adf-908f-71409075faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_alk, sample_dic, sample_tem, sample_sal, sample_sil, sample_phos =\\\n",
    "zip(*samples)\n",
    "sample_fco2 = calc_fCO2(sample_alk, sample_dic, sample_tem, sample_sal, sample_sil, sample_phos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6553912d-693c-4564-9742-0f30e6497c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453.50214571167703\n",
      "[328.11596538]\n",
      "(6000000,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.median(sample_fco2))\n",
    "print(calc_fCO2(tuple([2200e-6]), tuple([1950e-6]), tuple([18.5]), tuple([31]), tuple([67e-6]), tuple([2e-6])))\n",
    "print(sample_fco2.shape)\n",
    "print(type(sample_fco2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d62cadd1-7d5b-44f9-b67b-7314ba3e783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 5000_000\n",
    "\n",
    "train_fco2, valid_fco2 = np.split(sample_fco2, [ntrain])\n",
    "train_alk, valid_alk = np.split(np.array(sample_alk), [ntrain])\n",
    "train_dic, valid_dic = np.split(np.array(sample_dic), [ntrain])\n",
    "train_tem, valid_tem = np.split(np.array(sample_tem), [ntrain])\n",
    "train_sal, valid_sal = np.split(np.array(sample_sal), [ntrain])\n",
    "train_sil, valid_sil = np.split(np.array(sample_sil), [ntrain])\n",
    "train_phos, valid_phos = np.split(np.array(sample_phos), [ntrain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f9723b9f-5778-4b50-9fab-92bce16129a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some statistics:\n",
      "Mean for alk samples: 2.200027e-03, expected: 2.200000e-03\n",
      "Std for alk samples: 2.886953e-04, expected: 2.886751e-04\n",
      "-----\n",
      "Mean for dic samples: 1.950093e-03, expected: 1.950000e-03\n",
      "Std for dic samples: 2.205415e-04, expected: 2.204793e-04\n",
      "-----\n",
      "Mean for tem samples: 1.849863e+01, expected: 1.850000e+01\n",
      "Std for tem samples: 9.530802e+00, expected: 9.526279e+00\n",
      "-----\n",
      "Mean for sal samples: 3.099651e+01, expected: 3.100000e+01\n",
      "Std for sal samples: 6.927757e+00, expected: 6.928203e+00\n",
      "-----\n",
      "Mean for sil samples: 6.697189e-05, expected: 6.700000e-05\n",
      "Std for sil samples: 3.870030e-05, expected: 3.868247e-05\n",
      "-----\n",
      "Mean for phos samples: 1.999234e-06, expected: 2.000000e-06\n",
      "Std for phos samples: 1.154432e-06, expected: 1.154701e-06\n"
     ]
    }
   ],
   "source": [
    "sample_alk_mean = (1700e-6 + 2700e-6) / 2\n",
    "sample_alk_std = (2700e-6 - 1700e-6) / np.sqrt(12)\n",
    "\n",
    "sample_dic_mean = 1700e-6 + (2700e-6 - 1700e-6) / 4\n",
    "sample_dic_std = (2700e-6 - 1700e-6) * np.sqrt(7 / 144)\n",
    "\n",
    "sample_tem_mean = (2 + 35) / 2\n",
    "sample_tem_std = (35 - 2) / np.sqrt(12)\n",
    "\n",
    "sample_sal_mean = (19 + 43) / 2\n",
    "sample_sal_std = (43 - 19) / np.sqrt(12)\n",
    "\n",
    "sample_sil_mean = (134e-6 + 0e-6) / 2\n",
    "sample_sil_std = (134e-6 - 0e-6) / np.sqrt(12)\n",
    "\n",
    "sample_phos_mean = (4e-6 + 0e-6) / 2\n",
    "sample_phos_std = (4e-6 - 0e-6) / np.sqrt(12)\n",
    "\n",
    "print(\"Some statistics:\")\n",
    "print(\"Mean for alk samples: {:.6e}, expected: {:.6e}\".format(np.mean(train_alk), sample_alk_mean))\n",
    "print(\"Std for alk samples: {:.6e}, expected: {:.6e}\".format(np.std(train_alk), sample_alk_std))\n",
    "print(\"-----\")\n",
    "print(\"Mean for dic samples: {:.6e}, expected: {:.6e}\".format(np.mean(train_dic), sample_dic_mean))\n",
    "print(\"Std for dic samples: {:.6e}, expected: {:.6e}\".format(np.std(train_dic), sample_dic_std))\n",
    "print(\"-----\")\n",
    "print(\"Mean for tem samples: {:.6e}, expected: {:.6e}\".format(np.mean(train_tem), sample_tem_mean))\n",
    "print(\"Std for tem samples: {:.6e}, expected: {:.6e}\".format(np.std(train_tem), sample_tem_std))\n",
    "print(\"-----\")\n",
    "print(\"Mean for sal samples: {:.6e}, expected: {:.6e}\".format(np.mean(sample_sal), sample_sal_mean))\n",
    "print(\"Std for sal samples: {:.6e}, expected: {:.6e}\".format(np.std(sample_sal), sample_sal_std))\n",
    "print(\"-----\")\n",
    "print(\"Mean for sil samples: {:.6e}, expected: {:.6e}\".format(np.mean(train_sil), sample_sil_mean))\n",
    "print(\"Std for sil samples: {:.6e}, expected: {:.6e}\".format(np.std(train_sil), sample_sil_std))\n",
    "print(\"-----\")\n",
    "print(\"Mean for phos samples: {:.6e}, expected: {:.6e}\".format(np.mean(train_phos), sample_phos_mean))\n",
    "print(\"Std for phos samples: {:.6e}, expected: {:.6e}\".format(np.std(train_phos), sample_phos_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf96fd-d71d-4724-89e3-f50269240345",
   "metadata": {},
   "source": [
    "#### Normalize samples and train neural network with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2e39058f-ec81-456c-a9ec-388dde07b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means = np.array([sample_alk_mean, sample_dic_mean, sample_tem_mean,\n",
    "                         sample_sal_mean, sample_sil_mean, sample_phos_mean])\n",
    "sample_stds = np.array([sample_alk_std, sample_dic_std, sample_tem_std,\n",
    "                         sample_sal_std, sample_sil_std, sample_phos_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed0d400c-fb81-4cb2-9453-057fc3f5268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.concatenate([train_alk[:, np.newaxis], train_dic[:, np.newaxis], train_tem[:, np.newaxis],\n",
    "                               train_sal[:, np.newaxis], train_sil[:, np.newaxis], train_phos[:, np.newaxis]], axis=1)\n",
    "\n",
    "valid_features = np.concatenate([valid_alk[:, np.newaxis], valid_dic[:, np.newaxis], valid_tem[:, np.newaxis],\n",
    "                               valid_sal[:, np.newaxis], valid_sil[:, np.newaxis], valid_phos[:, np.newaxis]], axis=1)\n",
    "\n",
    "print(train_features.shape)\n",
    "train_features_normalized = (train_features - sample_means) / sample_stds\n",
    "valid_features_normalized = (valid_features - sample_means) / sample_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f36cf192-52e5-4370-beeb-dc28e51c08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verify that data is normalized.\n",
      "[ 9.47580989e-05  4.23186847e-04 -1.44276512e-04 -4.32910793e-04\n",
      " -7.26599596e-04 -6.63078680e-04]\n",
      "[1.00006983 1.00028241 1.00047477 0.99986704 1.00046103 0.99976755]\n"
     ]
    }
   ],
   "source": [
    "print(\"Verify that data is normalized.\")\n",
    "print(np.mean(train_features_normalized, axis=0))\n",
    "print(np.std(train_features_normalized, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "933cfa31-3848-4efe-a686-e90a1bceca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size, device=self.device)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size, device=self.device)\n",
    "        self.linear3 = nn.Linear(hidden_size, hidden_size, device=self.device)\n",
    "        self.linear4 = nn.Linear(hidden_size, output_size, device=self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = F.elu(self.linear1(x))\n",
    "        x = F.elu(self.linear2(x))\n",
    "        x = F.elu(self.linear3(x))\n",
    "        x = F.elu(self.linear4(x))\n",
    "        return x\n",
    "\n",
    "    def save(self, file_name='model.pth'):\n",
    "        model_folder_path = './model'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9edbbbae-1c19-42ed-86b4-a55bea37fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=6, out_features=64, bias=True)\n",
      "  (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (linear3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (linear4): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Number of trainable parameters in the model: 8833\n"
     ]
    }
   ],
   "source": [
    "model = MLP(6, 64, 1)\n",
    "print(model)\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable parameters in the model:\", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "09e2104f-fbc4-43e1-ad6b-456f6f882b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "learning_rate = 1e-3\n",
    "n_epochs = 100\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    batch_indices = np.random.randint(ntrain, size=batch_size)\n",
    "    \n",
    "    batch_features = np.take(train_features_normalized, batch_indices, axis=0)\n",
    "    batch_features_torch = torch.from_numpy(batch_features)\n",
    "\n",
    "    batch_labels = np.take(train_fco2, batch_indices)\n",
    "    batch_labels_torch = torch.from_numpy(batch_labels)\n",
    "\n",
    "    valid_features_torch = torch.from_numpy(valid_features_normalized)\n",
    "    valid_labels_torch = torch.from_numpy(valid_fco2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd580f9-8145-48ca-abc4-d9daced259ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(features, labels, lr, optim, loss, optimal=False):\n",
    "\n",
    "\tlosses = list()\n",
    "\trewards = list()\n",
    "\n",
    "\tfor x in range(_maxsteps):\n",
    "\n",
    "\t\tnsteps += 1\n",
    "\n",
    "\t\tif done:\n",
    "\t\t\tbreak\n",
    "\n",
    "\t\tif render:\n",
    "\t\t\tenv.render()\n",
    "\n",
    "\t\tcurr_state = observation\n",
    "\n",
    "\t\t# training time\n",
    "\t\tif not optimal:\n",
    "\n",
    "\t\t\t# Epsilon-greedy policy\n",
    "\t\t\trandnum = np.random.rand(1)\n",
    "\t\t\tif randnum < epsilon:\n",
    "\t\t\t\taction = env.action_space.sample()\n",
    "\t\t\telse:\n",
    "\t\t\t\tpass\n",
    "\t\t\t\t# TODO - feed the state into the Linear Q function and get the (best) action according to the Q-Learning formula\n",
    "\t\t\t\taction_vals = Q(torch.from_numpy(observation.astype(\"float32\")))#.detach().cpu().numpy()\n",
    "\t\t\t\taction = np.argmax(action_vals.detach().cpu().numpy())\n",
    "\n",
    "\t\t\t\tobservation, reward, done, _, info = env.step(action)\n",
    "\n",
    "\t\t\t\t# TODO - compute the MSE (i.e., the loss function between targets and predictions) according to the Q-Learning formula\n",
    "\t\t\t\toptim.zero_grad()\n",
    "\t\t\t\testimate = torch.max(action_vals)\n",
    "\t\t\t\tQ_next_state = Q(torch.from_numpy(observation.astype(\"float32\")))#.detach().cpu().numpy()\n",
    "\t\t\t\ttarget = reward + discount * torch.max(Q_next_state)\n",
    "\t\t\t\tl = loss(target, estimate)\n",
    "\t\t\t\t# the targets should be: reward + discount * np.max(Q(next_state))\n",
    "\t\t\t\t# the estimate should be: current estimate of Q(, action)\n",
    "\t\t\t\t#loss = crit(targets, estimate)\n",
    "\t\t\t\tl.backward()\n",
    "\t\t\t\toptim.step()\n",
    "\t\t\t\tlosses.append(l.detach().cpu().numpy())\n",
    "\t\t\t\trewards.append(reward)\n",
    "\n",
    "\t\t# evaluation time\n",
    "\t\telse:\n",
    "\t\t\t# TODO - feed the state into the Linear Q function and get the (best) action according to the Q-Learning formula\n",
    "\t\t\taction_vals = Q(torch.from_numpy(observation.astype(\"float32\")))#.detach().cpu().numpy()\n",
    "\t\t\taction = np.argmax(action_vals.detach().cpu().numpy())\n",
    "\t\t\tobservation, reward, done, _, info = env.step(action)\n",
    "\n",
    "\treturn rewards, losses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
