{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61fc216-3068-4b66-8db9-bf4ecdaf1a47",
   "metadata": {},
   "source": [
    "#### Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4602702-c7e7-4113-b66a-05bb086276d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0,'../../mocsy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98506a5e-a778-479d-a929-11b5ee8348dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import mocsy\n",
    "from mocsy import mvars\n",
    "from mocsy import mrhoinsitu\n",
    "from mocsy import mrho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7040edad-9ecb-4263-b4aa-6c8d7092e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d1bdd-e438-434d-90cf-f5ac0c5526c9",
   "metadata": {},
   "source": [
    "# Creation of the four training data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3727c-8384-4dd4-b17c-1f53ace14d4a",
   "metadata": {},
   "source": [
    "#### Read in the observational data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cce78a4-688c-4833-868f-3f3bfa6ca3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for tos, use the ESA CCI and C3S product until October 2022, then Armor3D for November and December\n",
      "for siconc, use the ESA CCI and C3S product until October 2022, then METOFFICE Ostia for November and December\n",
      "for chlos, use the climatological mean value before September 1997\n",
      "for co2, use a global representative value, given by the annual average measurement from Manua Loa, Hawaii\n"
     ]
    }
   ],
   "source": [
    "print(\"for tos, use the ESA CCI and C3S product until October 2022, then Armor3D for November and December\")\n",
    "print(\"for siconc, use the ESA CCI and C3S product until October 2022, then METOFFICE Ostia for November and December\")\n",
    "print(\"for chlos, use the climatological mean value before September 1997\")\n",
    "print(\"for co2, use a global representative value, given by the annual average measurement from Manua Loa, Hawaii\")\n",
    "ds_cci = xr.open_dataset(\"../data/ESACCI_and_C3S-GLO-SST-L4-REP-OBS-SST_multi-vars_1x1grid_1982-01-01-2022-10-31_monmean.nc\"\n",
    "                    ).sel(time=slice('1993-01-01', '2022-10-31'))\n",
    "ds_ostia = xr.open_dataset(\"../data/METOFFICE-GLO-SST-L4-NRT-OBS-SST-V2_multi-vars_1x1grid_2022-11-01-2022-12-31_monmean.nc\")\n",
    "ds_armor = xr.open_dataset(\"../data/dataset-armor-3d-rep-monthly_multi-vars_1x1grid_coarsened_0.00m_1993-01-01-2022-12-01.nc\")\n",
    "ds_ssh = xr.open_dataset(\n",
    "    \"../data/cmems_obs-sl_glo_phy-ssh_my_allsat-l4-duacs-0.25deg_P1D_adt_1x1grid_coarsened_1993-01-01-2022-12-31_monmean.nc\")\n",
    "ds_globcol = xr.open_dataset(\"../data/cmems_obs-oc_glo_bgc-plankton_my_l4-multi-4km_P1M_multi-vars_1x1grid_1997-09-01-2022-12-01.nc\")\n",
    "ds_globcol_clim = xr.open_dataset(\n",
    "    \"../data/cmems_obs-oc_glo_bgc-plankton_my_l4-multi-4km_P1M_multi-vars_1x1grid_1997-09-01-2022-12-01_ymonmean.nc\")\n",
    "df_co2 = pd.read_csv(\"../data/monthly_in_situ_co2_mlo_no_header.csv\")\n",
    "ds_era5 = xr.open_dataset(\"../data/era5_winds_1993_2022_1x1grid.nc\")\n",
    "ds_socat = xr.open_dataset(\"../data/SOCATv2023_tracks_gridded_monthly.nc\").sel(tmnth=slice('1993-01-01', '2022-12-31'))\n",
    "ds_bgcargo = xr.open_dataset(\"../data/202405-BgcArgoSprof_pH_gridded.nc\")\n",
    "ds_glodap_4vars = xr.open_dataset(\"../data/GLODAPv2.2023_gridded_talk_tco2_silicate_phosphate.nc\")\n",
    "ds_glodap_2vars = xr.open_dataset(\"../data/GLODAPv2.2023_gridded_talk_tco2_only.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "011af99c-93a0-4590-84e1-1c4c57fee0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "data[\"tos\"] = np.concatenate([ds_cci.analysed_sst.values - 273.15, # ESA CCI and C3S is in Kelvin units\n",
    "                      ds_armor.to.squeeze().values[-2:, :, :]], axis=0)\n",
    "\n",
    "data[\"siconc\"] = np.concatenate([ds_cci.sea_ice_fraction.values,\n",
    "                         ds_ostia.sea_ice_fraction.values], axis=0) * 100\n",
    "# to have concentration in range 0 100, as in models\n",
    "\n",
    "data[\"sos\"] = ds_armor.so.squeeze().values\n",
    "#Remove samples with sos < 10, since these were also removed during training of CMIP6 base model\"\n",
    "data[\"sos\"][data[\"sos\"] < 10] = np.nan\n",
    "\n",
    "data[\"mlotst\"] = ds_armor.mlotst.squeeze().values\n",
    "\n",
    "data[\"zos\"] = ds_ssh.adt.squeeze().values\n",
    "\n",
    "data[\"chlos\"] = np.concatenate([np.concatenate([ds_globcol_clim.CHL.values for i in range(5)],\n",
    "                                                  axis=0)[:-4, :, :], ds_globcol.CHL.values], axis=0) * 1e-6\n",
    "# to go from mg m-3 to kg m-3 \n",
    "#data[\"chlos\"][np.logical_and(np.isnan(data[\"chlos\"]), np.isfinite(data[\"tos\"]))] = 0\n",
    "\n",
    "df_co2_yearmean = df_co2[['  Yr', '     CO2']].groupby('  Yr').mean()\n",
    "co2_scalar = df_co2_yearmean.loc[1993:2022]['     CO2'].values\n",
    "data[\"co2\"] = np.concatenate([co2_year * np.ones((12, 180, 360)) for co2_year in co2_scalar], axis=0)\n",
    "\n",
    "data[\"uas\"] = ds_era5.u10.values\n",
    "data[\"vas\"] = ds_era5.v10.values\n",
    "\n",
    "data[\"fco2\"] = ds_socat.fco2_ave_weighted.values\n",
    "\n",
    "data[\"ph\"] = ds_bgcargo.PH_IN_SITU_TOTAL_ADJUSTED_gridded.values\n",
    "\n",
    "data[\"talkos_4\"] = ds_glodap_4vars.G2talk.values * 1e-6 # to go from mumol kg-1 to mol kg-1\n",
    "data[\"dissicos_4\"] = ds_glodap_4vars.G2tco2.values * 1e-6\n",
    "data[\"sios_4\"] = ds_glodap_4vars.G2silicate.values * 1e-6\n",
    "data[\"po4os_4\"] = ds_glodap_4vars.G2phosphate.values * 1e-6\n",
    "\n",
    "data[\"talkos_2\"] = ds_glodap_2vars.G2talk.values * 1e-6\n",
    "data[\"dissicos_2\"] = ds_glodap_2vars.G2tco2.values * 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "673c4e47-392c-430b-8ef5-752fb3c899fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"lat\"] = np.repeat(np.repeat(np.arange(-89.5, 90)[np.newaxis, :],\n",
    "                         360, axis=0)[:, :, np.newaxis], 360, axis=2)\n",
    "\n",
    "data[\"lon\"] = np.repeat(np.repeat(np.arange(-179.5, 180)[np.newaxis, :],\n",
    "                         180, axis=0)[np.newaxis, :, :], 360, axis=0)\n",
    "data[\"mon\"] = np.repeat(np.repeat(np.array([i % 12 for i in range(360)])[:, np.newaxis],\n",
    "                          180, axis=1)[:, :, np.newaxis], 360, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "901e758a-89b1-48cd-ad44-79aff34902fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-nan grid cells for tos: 16363300\n",
      "Number of non-nan grid cells for siconc: 16365762\n",
      "Number of non-nan grid cells for sos: 16059621\n",
      "Number of non-nan grid cells for mlotst: 16015927\n",
      "Number of non-nan grid cells for zos: 13973267\n",
      "Number of non-nan grid cells for chlos: 14220761\n",
      "Number of non-nan grid cells for co2: 23328000\n",
      "Number of non-nan grid cells for uas: 23328000\n",
      "Number of non-nan grid cells for vas: 23328000\n",
      "Number of non-nan grid cells for lat: 23328000\n",
      "Number of non-nan grid cells for lon: 23328000\n",
      "Number of non-nan grid cells for mon: 23328000\n"
     ]
    }
   ],
   "source": [
    "predictors = [\"tos\", \"siconc\", \"sos\", \"mlotst\", \"zos\", \"chlos\", \"co2\",\n",
    "              \"uas\", \"vas\", \"lat\", \"lon\", \"mon\"]\n",
    "for predictor in predictors:\n",
    "    print(\"Number of non-nan grid cells for {}: {}\". format(\n",
    "        predictor, np.sum(np.isfinite(data[predictor]))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35d44b4e-96dd-481a-9b68-2330f5d1bbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum and maximum for tos: -2.11e+00, 3.57e+01\n",
      "Minimum and maximum for siconc: 0.00e+00, 1.00e+02\n",
      "Minimum and maximum for sos: 1.00e+01, 4.22e+01\n",
      "Minimum and maximum for mlotst: 1.01e+01, 2.14e+03\n",
      "Minimum and maximum for zos: -1.57e+00, 2.20e+00\n",
      "Minimum and maximum for chlos: 1.00e-08, 6.50e-05\n",
      "Minimum and maximum for co2: 3.57e+02, 4.18e+02\n",
      "Minimum and maximum for uas: -1.75e+01, 1.42e+01\n",
      "Minimum and maximum for vas: -1.58e+01, 2.01e+01\n",
      "Minimum and maximum for lat: -8.95e+01, 8.95e+01\n",
      "Minimum and maximum for lon: -1.80e+02, 1.80e+02\n",
      "Minimum and maximum for mon: 0.00e+00, 1.10e+01\n"
     ]
    }
   ],
   "source": [
    "for predictor in predictors:\n",
    "    print(\"Minimum and maximum for {}: {:.2e}, {:.2e}\". format(\n",
    "        predictor, np.nanmin(data[predictor]), np.nanmax(data[predictor])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f2037db-b302-4c26-a2cd-511412075adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-nan grid cells for fco2: 341467\n",
      "Number of non-nan grid cells for ph: 10091\n",
      "Number of non-nan grid cells for talkos_4: 11254\n",
      "Number of non-nan grid cells for dissicos_4: 11254\n",
      "Number of non-nan grid cells for sios_4: 11254\n",
      "Number of non-nan grid cells for po4os_4: 11254\n",
      "Number of non-nan grid cells for talkos_2: 4182\n",
      "Number of non-nan grid cells for dissicos_2: 4182\n"
     ]
    }
   ],
   "source": [
    "labels = [\"fco2\", \"ph\", \"talkos_4\", \"dissicos_4\", \"sios_4\", \"po4os_4\", \"talkos_2\", \"dissicos_2\"]\n",
    "for label in labels:\n",
    "    print(\"Number of non-nan grid cells for {}: {}\". format(\n",
    "        label, np.sum(np.isfinite(data[label]))\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8cce77a-bc1c-4971-a2de-2d67dc56cb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum and maximum for fco2: 4.45e+01, 4.31e+03\n",
      "Minimum and maximum for ph: 7.67e+00, 8.36e+00\n",
      "Minimum and maximum for talkos_4: 1.01e-03, 2.61e-03\n",
      "Minimum and maximum for dissicos_4: 1.12e-03, 2.40e-03\n",
      "Minimum and maximum for sios_4: 9.50e-09, 1.36e-04\n",
      "Minimum and maximum for po4os_4: 2.88e-09, 2.28e-06\n",
      "Minimum and maximum for talkos_2: 1.31e-03, 2.63e-03\n",
      "Minimum and maximum for dissicos_2: 1.26e-03, 2.30e-03\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(\"Minimum and maximum for {}: {:.2e}, {:.2e}\". format(\n",
    "        label, np.nanmin(data[label]), np.nanmax(data[label])\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f0137-bd68-4a77-9e74-bac8c9d719fc",
   "metadata": {},
   "source": [
    "#### Creation of training data\n",
    "\n",
    "* selection of data from the gridded fields specific to the 4 training types: socat, bgcargo, glodap_4, glodap_2\n",
    "* since all four training types train the same neural network, I want to use the same normalisation on all four training sets.\n",
    "* calculate global means and standard deviations after concatenating the predictor arrays from the four training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "136cdc35-6605-46d8-9567-e2ecb015f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SOCAT samples: 341467\n",
      "Number of SOCAT samples where all predictors available: 324296 (95.0 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of SOCAT samples: {}\".format(np.sum(np.isfinite(data[\"fco2\"]))))\n",
    "# check how many grid cells have non-nan values in socat fco2 and all predictor fields\n",
    "# (some predictors left out because they have no missing values)\n",
    "is_socat_training_sample = np.isfinite(data[\"fco2\"] * data[\"siconc\"] * data[\"tos\"] * data[\"sos\"]\n",
    "                                       * data[\"mlotst\"] * data[\"zos\"] * data[\"chlos\"])\n",
    "print(\"Number of SOCAT samples where all predictors available: {} ({:.1f} %)\".format(\n",
    "    np.sum(is_socat_training_sample),\n",
    "    100 * np.sum(is_socat_training_sample) / np.sum(np.isfinite(data[\"fco2\"]))))\n",
    "\n",
    "data_socat = {}\n",
    "for key in [\"fco2\"] + predictors:\n",
    "    data_socat[key] = data[key][is_socat_training_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "744bd0a9-ca2b-40ed-ba72-46050b9c75c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of BGC-ARGO samples: 10091\n",
      "Number of BGC-ARGO samples where all predictors available: 9449 (93.6 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of BGC-ARGO samples: {}\".format(np.sum(np.isfinite(data[\"ph\"]))))\n",
    "is_bgcargo_training_sample = np.isfinite(data[\"ph\"] * data[\"siconc\"] * data[\"tos\"] * data[\"sos\"]\n",
    "                                       * data[\"mlotst\"] * data[\"zos\"] * data[\"chlos\"])\n",
    "print(\"Number of BGC-ARGO samples where all predictors available: {} ({:.1f} %)\".format(\n",
    "    np.sum(is_bgcargo_training_sample),\n",
    "    100 * np.sum(is_bgcargo_training_sample) / np.sum(np.isfinite(data[\"ph\"]))))\n",
    "\n",
    "data_bgcargo = {}\n",
    "for key in [\"ph\"] + predictors:\n",
    "    data_bgcargo[key] = data[key][is_bgcargo_training_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82160449-a0bc-4301-aa45-71babe987ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GLODAP_4 samples: 11254\n",
      "Number of GLODAP_4 samples where all predictors available: 10629 (94.4 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of GLODAP_4 samples: {}\".format(np.sum(np.isfinite(data[\"talkos_4\"]))))\n",
    "is_glodap_4_training_sample = np.isfinite(data[\"talkos_4\"] * data[\"siconc\"] * data[\"tos\"] * data[\"sos\"]\n",
    "                                       * data[\"mlotst\"] * data[\"zos\"] * data[\"chlos\"])\n",
    "print(\"Number of GLODAP_4 samples where all predictors available: {} ({:.1f} %)\".format(\n",
    "    np.sum(is_glodap_4_training_sample),\n",
    "    100 * np.sum(is_glodap_4_training_sample) / np.sum(np.isfinite(data[\"talkos_4\"]))))\n",
    "\n",
    "data_glodap_4 = {}\n",
    "for key in [\"talkos_4\", \"dissicos_4\", \"sios_4\", \"po4os_4\"] + predictors:\n",
    "    data_glodap_4[key] = data[key][is_glodap_4_training_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fabeb65-2047-44f4-95cf-4f19ae0cec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GLODAP_2 samples: 4182\n",
      "Number of GLODAP_2 samples where all predictors available: 3959 (94.7 %)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of GLODAP_2 samples: {}\".format(np.sum(np.isfinite(data[\"talkos_2\"]))))\n",
    "is_glodap_2_training_sample = np.isfinite(data[\"talkos_2\"] * data[\"siconc\"] * data[\"tos\"] * data[\"sos\"]\n",
    "                                       * data[\"mlotst\"] * data[\"zos\"] * data[\"chlos\"])\n",
    "print(\"Number of GLODAP_2 samples where all predictors available: {} ({:.1f} %)\".format(\n",
    "    np.sum(is_glodap_2_training_sample),\n",
    "    100 * np.sum(is_glodap_2_training_sample) / np.sum(np.isfinite(data[\"talkos_2\"]))))\n",
    "\n",
    "data_glodap_2 = {}\n",
    "for key in [\"talkos_2\", \"dissicos_2\"] + predictors:\n",
    "    data_glodap_2[key] = data[key][is_glodap_2_training_sample]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149fe10-7370-48cd-8bf5-0d970456a711",
   "metadata": {},
   "source": [
    "# Preprocessing of data for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849bf759-7f40-40aa-9782-a2d142cdec8a",
   "metadata": {},
   "source": [
    "#### Transform mon to mon_sin and mon_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8612e5f-08c8-4f26-9cfc-34ebe569d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_dict in [data_socat, data_bgcargo, data_glodap_4, data_glodap_2]:\n",
    "    data_dict[\"mon_sin\"] = np.sin(data_dict[\"mon\"] / 12 * 2 * np.pi)\n",
    "    data_dict[\"mon_cos\"] = np.cos(data_dict[\"mon\"] / 12 * 2 * np.pi)\n",
    "    del data_dict[\"mon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679ae25-8c34-4ed8-a861-94c2728658a1",
   "metadata": {},
   "source": [
    "#### Transform lat and lon\n",
    "\n",
    "Following Gade et al., 2010: A Non-singular Horizontal Position Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4152dfc1-e8ba-4975-b0d8-70dd07eef621",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_dict in [data_socat, data_bgcargo, data_glodap_4, data_glodap_2]:\n",
    "    data_dict[\"nvector1\"] = np.sin(data_dict[\"lat\"] / 360 * 2 * np.pi)\n",
    "    data_dict[\"nvector2\"] = np.sin(data_dict[\"lon\"] / 360 * 2 * np.pi)\\\n",
    "    * np.cos(data_dict[\"lat\"] / 360 * 2 * np.pi)\n",
    "    data_dict[\"nvector3\"] = - np.cos(data_dict[\"lon\"] / 360 * 2 * np.pi)\\\n",
    "    * np.cos(data_dict[\"lat\"] / 360 * 2 * np.pi)\n",
    "    del data_dict[\"lon\"]\n",
    "    del data_dict[\"lat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bca3f6-7b6e-4dbd-ba0d-7c507ad8844e",
   "metadata": {},
   "source": [
    "#### Normalize talkos, dissicos, sios, and po4os in the GLODAP_4 and GLODAP_2 training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93ad35a4-eed0-4e46-9466-a9585c35ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alk_range = [1000e-6, 3000e-6]\n",
    "dic_range = [1000e-6, 3000e-6]\n",
    "tem_range = [-2, 35]\n",
    "sal_range = [10, 50]\n",
    "sil_range = [0, 134e-6]\n",
    "phos_range = [0, 4e-6]\n",
    "\n",
    "sample_means = {\"talkos\":(alk_range[0] + alk_range[1]) / 2,\n",
    "                 \"dissicos\":dic_range[0] + (dic_range[1] - dic_range[0]) / 4,\n",
    "                 \"tos\":(tem_range[0] + tem_range[1]) / 2,\n",
    "                 \"sos\":(sal_range[0] + sal_range[1]) / 2,\n",
    "                 \"sios\":(sil_range[0] + sil_range[1]) / 2,\n",
    "                 \"po4os\":(phos_range[0] + phos_range[1]) / 2}\n",
    "\n",
    "sample_stds = {\"talkos\":(alk_range[1] - alk_range[0]) / np.sqrt(12),\n",
    "                 \"dissicos\":(dic_range[1] - dic_range[0]) * np.sqrt(7 / 144),\n",
    "                 \"tos\":(tem_range[1] - tem_range[0]) / np.sqrt(12),\n",
    "                 \"sos\":(sal_range[1] - sal_range[0]) / np.sqrt(12),\n",
    "                 \"sios\":(sil_range[1] - sil_range[0]) / np.sqrt(12),\n",
    "                 \"po4os\":(phos_range[1] - phos_range[0]) / np.sqrt(12)}\n",
    "\n",
    "# normalize all four concentrations for glodap_4\n",
    "data_glodap_4[\"talkos_4\"] = (data_glodap_4[\"talkos_4\"]\n",
    "                             - sample_means[\"talkos\"]) / sample_stds[\"talkos\"]\n",
    "data_glodap_4[\"dissicos_4\"] = (data_glodap_4[\"dissicos_4\"]\n",
    "                               - sample_means[\"dissicos\"]) / sample_stds[\"dissicos\"]\n",
    "data_glodap_4[\"sios_4\"] = (data_glodap_4[\"sios_4\"]\n",
    "                           - sample_means[\"sios\"]) / sample_stds[\"sios\"]\n",
    "data_glodap_4[\"po4os_4\"] = (data_glodap_4[\"po4os_4\"]\n",
    "                            - sample_means[\"po4os\"]) / sample_stds[\"po4os\"]\n",
    "\n",
    "# then normalize all four concentrations for glodap_4\n",
    "data_glodap_2[\"talkos_2\"] = (data_glodap_2[\"talkos_2\"]\n",
    "                             - sample_means[\"talkos\"]) / sample_stds[\"talkos\"]\n",
    "data_glodap_2[\"dissicos_2\"] = (data_glodap_2[\"dissicos_2\"]\n",
    "                               - sample_means[\"dissicos\"]) / sample_stds[\"dissicos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee75728-16ca-4d66-a593-20bce2359edb",
   "metadata": {},
   "source": [
    "#### Log-transform mlotst and chlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aecad3f6-b287-4b37-8296-7b1f9379cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    return (array - np.mean(array)) / np.std(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5088a280-8c9a-46a2-90d6-afe260aba9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlotst statistic (SOCAT training data):  0.23848178659560587\n",
      "mlotst statistic with log transform (SOCAT training data):  0.054752194789443986\n"
     ]
    }
   ],
   "source": [
    "print(\"mlotst statistic (SOCAT training data): \",\n",
    "      stats.kstest(normalize(data_socat[\"mlotst\"]), stats.norm.cdf)[0])\n",
    "print(\"mlotst statistic with log transform (SOCAT training data): \",\n",
    "      stats.kstest(normalize(np.log(data_socat[\"mlotst\"])), stats.norm.cdf)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243f6802-b52a-429c-960b-5b70f44e3ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlotst statistic (SOCAT training data):  0.31854699866401254\n",
      "mlotst statistic with log transform (SOCAT training data):  0.05314087501933262\n"
     ]
    }
   ],
   "source": [
    "print(\"mlotst statistic (SOCAT training data): \",\n",
    "      stats.kstest(normalize(data_socat[\"chlos\"]), stats.norm.cdf)[0])\n",
    "print(\"mlotst statistic with log transform (SOCAT training data): \",\n",
    "      stats.kstest(normalize(np.log(data_socat[\"chlos\"])), stats.norm.cdf)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4130fd92-345d-4703-b769-64592c5cf5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'mlotst')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGxCAYAAACwbLZkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjHklEQVR4nO3df1BVdeL/8dcV5KIGGKL8SCAqLSdcKygF1w0tKDR23dqkcUa0VScGy1XWpsiZvDmN7MdZzVrFH5tGTuYybmQ2Mdn9TIGatpME1abT1mqBCTHQLiAVipzvH3683278kHtF3lx4PmbuTPd9z+G+75kz47P3uT9slmVZAgAAMGSI6QkAAIDBjRgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBcMV89dVXstlsKiws9HjfY8eOyeFw6KuvvvLqudesWaO9e/d6tS+AvkWMAOiXjh07pmeeeYYYAQYBYgQAABhFjADolsPhkM1m0yeffKIHH3xQISEhCg0NVW5urtra2vT555/r3nvvVVBQkK699lqtXbv2kn/z0KFDuuuuuxQUFKThw4crOTlZb731luvxwsJCPfjgg5Kk6dOny2azuV3uqaio0H333acxY8bIbrcrKipKs2bN0qlTpyRJNptNLS0tevnll137pqSk9PqxAdA7iBEAPTJnzhxNmjRJr732mhYvXqznnntOy5cv1+zZszVr1iy9/vrrmjFjhp544gkVFxd3+XfKyso0Y8YMNTY2avv27dq9e7eCgoKUkZGhoqIiSdKsWbO0Zs0aSdKmTZt05MgRHTlyRLNmzVJLS4tSU1P17bffatOmTXI6ndqwYYNiYmLU3NwsSTpy5IiGDRummTNnuvYtKCi48gcJgHcsAOjGqlWrLEnWunXr3MZvueUWS5JVXFzsGjt37pw1evRo6/7777csy7JOnjxpSbJeeukl1zZTpkyxxowZYzU3N7vG2trarPj4eGvs2LFWe3u7ZVmWtWfPHkuS9d5777k979GjRy1J1t69e7ud94gRI6z58+d78YoB9DVWRgD0yH333ed2f8KECbLZbEpPT3eN+fv764YbbtDXX3/d6d9oaWnRP/7xD/3ud7/TVVdd5Rr38/PTvHnzdOrUKX3++efdzuOGG27Q1VdfrSeeeEJbtmzRsWPHLuNVAegPiBEAPRIaGup2PyAgQMOHD1dgYGCH8R9//LHTv/Gf//xHlmUpMjKyw2NRUVGSpIaGhm7nERISorKyMt1yyy166qmndPPNNysqKkqrVq3SuXPnPHlJAPoJYgRAn7n66qs1ZMgQ1dTUdHjs9OnTkqSwsLBL/p2JEyfqb3/7mxoaGlRZWanMzEytXr1a69at6/U5A7jyiBEAfWbEiBGaPHmyiouL9cMPP7jG29vb9corr2js2LEaP368JMlut0uS23Y/Z7PZNGnSJD333HMaOXKkPvroI9djdru9230B9B/+picAYHDJz89Xamqqpk+frhUrViggIEAFBQX65z//qd27d8tms0mS4uPjJUnbtm1TUFCQAgMDFRcX5/pkzOzZs3XdddfJsiwVFxfrv//9r1JTU13PM3HiRJWWlurNN99UZGSkgoKCdOONNxp5zQC6x8oIgD5155136t1339WIESO0YMECPfTQQ2psbNS+ffuUmZnp2i4uLk4bNmzQxx9/rJSUFN1+++168803NW7cOI0cOVJr167Vr3/9az344IP66KOPVFhYqMWLF7v2f/755zVu3Dg99NBDuv322/XII4+YeLkAesBmWZZlehIAAGDwYmUEAAAYRYwAAACjiBEAAGAUMQIAAIwiRgAAgFHECAAAMMonvvSsvb1dp0+fVlBQkOsLkQAAQP9mWZaam5sVFRWlIUO6Xv/wiRg5ffq0oqOjTU8DAAB4obq6WmPHju3ycZ+IkaCgIEkXXkxwcLDh2QAAgJ5oampSdHS069/xrvhEjFy8NBMcHEyMAADgYy71FgvewAoAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAKGIEAAAYRYwAAACjiBEAAGAUMQIAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAKGIEAAAY5W96Ar7O4ej+PgAA6B4rIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGOVxjBw4cEAZGRmKioqSzWbT3r17u92+uLhYqampGj16tIKDg5WUlKT9+/d7O18AADDAeBwjLS0tmjRpkjZu3Nij7Q8cOKDU1FSVlJSovLxc06dPV0ZGhioqKjyeLAAAGHj8Pd0hPT1d6enpPd5+w4YNbvfXrFmjN954Q2+++aZuvfVWT58eAAAMMB7HyOVqb29Xc3OzQkNDu9ymtbVVra2trvtNTU19MTUAAGBAn7+Bdd26dWppadGcOXO63CY/P18hISGuW3R0dB/OEAAA9KU+jZHdu3fL4XCoqKhIY8aM6XK7vLw8NTY2um7V1dV9OEsAANCX+uwyTVFRkRYuXKg9e/bo7rvv7nZbu90uu93eRzMDAAAm9cnKyO7du7VgwQK9+uqrmjVrVl88JQAA8BEer4ycOXNGX375pev+yZMnVVlZqdDQUMXExCgvL0/ffPONdu7cKelCiGRlZen555/XlClTVFtbK0kaNmyYQkJCeullAAAAX+XxysjRo0d16623uj6Wm5ubq1tvvVVPP/20JKmmpkZVVVWu7bdu3aq2tjYtWbJEkZGRrtsf/vCHXnoJAADAl3m8MpKSkiLLsrp8vLCw0O1+aWmpp08BAAAGEX6bBgAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACMIkYAAIBRxAgAADCKGAEAAEYRIwAAwChiBAAAGEWMAAAAo4gRAABgFDECAACM8jhGDhw4oIyMDEVFRclms2nv3r2X3KesrEwJCQkKDAzUddddpy1btngzVwAAMAB5HCMtLS2aNGmSNm7c2KPtT548qZkzZ2ratGmqqKjQU089paVLl+q1117zeLIAAGDg8fd0h/T0dKWnp/d4+y1btigmJkYbNmyQJE2YMEFHjx7Vn//8Zz3wwAOePj0AABhgrvh7Ro4cOaK0tDS3sXvuuUdHjx7VuXPnOt2ntbVVTU1NbjcAADAwXfEYqa2tVXh4uNtYeHi42traVF9f3+k++fn5CgkJcd2io6Ov9DQBAIAhffJpGpvN5nbfsqxOxy/Ky8tTY2Oj61ZdXX3F5wgAAMzw+D0jnoqIiFBtba3bWF1dnfz9/TVq1KhO97Hb7bLb7Vd6agAAoB+44isjSUlJcjqdbmPvvPOOEhMTNXTo0Cv99AAAoJ/zOEbOnDmjyspKVVZWSrrw0d3KykpVVVVJunCJJSsry7V9dna2vv76a+Xm5ur48ePasWOHtm/frhUrVvTOKwAAAD7N48s0R48e1fTp0133c3NzJUnz589XYWGhampqXGEiSXFxcSopKdHy5cu1adMmRUVF6YUXXuBjvQAAQJIXMZKSkuJ6A2pnCgsLO4zdeeed+uijjzx9KgAAMAjw2zQAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAof9MTGGgcjp6NAQCAC1gZAQAARhEjAADAKK9ipKCgQHFxcQoMDFRCQoIOHjzY7fa7du3SpEmTNHz4cEVGRurhhx9WQ0ODVxMGAAADi8cxUlRUpGXLlmnlypWqqKjQtGnTlJ6erqqqqk63P3TokLKysrRw4UJ99tln2rNnjz788EMtWrTosicPAAB8n8cxsn79ei1cuFCLFi3ShAkTtGHDBkVHR2vz5s2dbv/BBx/o2muv1dKlSxUXF6df/vKXeuSRR3T06NHLnjwAAPB9HsXI2bNnVV5errS0NLfxtLQ0HT58uNN9kpOTderUKZWUlMiyLH377bf6+9//rlmzZnX5PK2trWpqanK7AQCAgcmjGKmvr9f58+cVHh7uNh4eHq7a2tpO90lOTtauXbuUmZmpgIAARUREaOTIkfrLX/7S5fPk5+crJCTEdYuOjvZkmr3OUeqQo9RhdA4AAAxUXr2B1Wazud23LKvD2EXHjh3T0qVL9fTTT6u8vFxvv/22Tp48qezs7C7/fl5enhobG1236upqb6YJAAB8gEdfehYWFiY/P78OqyB1dXUdVksuys/P19SpU/X4449Lkn7xi19oxIgRmjZtmp599llFRkZ22Mdut8tut3syNQAA4KM8WhkJCAhQQkKCnE6n27jT6VRycnKn+3z//fcaMsT9afz8/CRdWFEBAACDm8eXaXJzc/Xiiy9qx44dOn78uJYvX66qqirXZZe8vDxlZWW5ts/IyFBxcbE2b96sEydO6P3339fSpUt1xx13KCoqqvdeCQAA8Eke/zZNZmamGhoatHr1atXU1Cg+Pl4lJSWKjY2VJNXU1Lh958iCBQvU3NysjRs36o9//KNGjhypGTNm6H/+539671UAAACfZbN84FpJU1OTQkJC1NjYqODg4D5//oufpHGkODo+1nHIq20AABhoevrvN79NAwAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGeRUjBQUFiouLU2BgoBISEnTw4MFut29tbdXKlSsVGxsru92u66+/Xjt27PBqwgAAYGDx93SHoqIiLVu2TAUFBZo6daq2bt2q9PR0HTt2TDExMZ3uM2fOHH377bfavn27brjhBtXV1amtre2yJw8AAHyfxzGyfv16LVy4UIsWLZIkbdiwQfv379fmzZuVn5/fYfu3335bZWVlOnHihEJDQyVJ11577eXNGgAADBgeXaY5e/asysvLlZaW5jaelpamw4cPd7rPvn37lJiYqLVr1+qaa67R+PHjtWLFCv3www9dPk9ra6uamprcbgAAYGDyaGWkvr5e58+fV3h4uNt4eHi4amtrO93nxIkTOnTokAIDA/X666+rvr5eOTk5+u6777p830h+fr6eeeYZT6YGAAB8lFdvYLXZbG73LcvqMHZRe3u7bDabdu3apTvuuEMzZ87U+vXrVVhY2OXqSF5enhobG1236upqb6YJAAB8gEcrI2FhYfLz8+uwClJXV9dhteSiyMhIXXPNNQoJCXGNTZgwQZZl6dSpUxo3blyHfex2u+x2uydTAwAAPsqjlZGAgAAlJCTI6XS6jTudTiUnJ3e6z9SpU3X69GmdOXPGNfavf/1LQ4YM0dixY72YMgAAGEg8vkyTm5urF198UTt27NDx48e1fPlyVVVVKTs7W9KFSyxZWVmu7efOnatRo0bp4Ycf1rFjx3TgwAE9/vjj+v3vf69hw4b13isBAAA+yeOP9mZmZqqhoUGrV69WTU2N4uPjVVJSotjYWElSTU2NqqqqXNtfddVVcjqdeuyxx5SYmKhRo0Zpzpw5evbZZ3vvVQAAAJ/lcYxIUk5OjnJycjp9rLCwsMPYTTfd1OHSDgAAgMRv0wAAAMOIEQAAYBQxAgAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYgQAABhFjAAAAKOIEQAAYBQxAgAAjCJGAACAUV79UB4843B0fx8AgMGMlREAAGAUMQIAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAKGIEAAAYRYwAAACjiBEAAGAUMQIAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAKGIEAAAYRYwAAACjiBEAAGAUMQIAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAKGIEAAAYRYwAAACjiBEAAGAUMQIAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAKGIEAAAY5VWMFBQUKC4uToGBgUpISNDBgwd7tN/7778vf39/3XLLLd48LQAAGIA8jpGioiItW7ZMK1euVEVFhaZNm6b09HRVVVV1u19jY6OysrJ01113eT1ZAAAw8HgcI+vXr9fChQu1aNEiTZgwQRs2bFB0dLQ2b97c7X6PPPKI5s6dq6SkJK8nCwAABh6PYuTs2bMqLy9XWlqa23haWpoOHz7c5X4vvfSS/v3vf2vVqlU9ep7W1lY1NTW53QAAwMDkUYzU19fr/PnzCg8PdxsPDw9XbW1tp/t88cUXevLJJ7Vr1y75+/v36Hny8/MVEhLiukVHR3syTQAA4EO8egOrzWZzu29ZVocxSTp//rzmzp2rZ555RuPHj+/x38/Ly1NjY6PrVl1d7c00AQCAD+jZUsX/CQsLk5+fX4dVkLq6ug6rJZLU3Nyso0ePqqKiQo8++qgkqb29XZZlyd/fX++8845mzJjRYT+73S673e7J1AAAgI/yaGUkICBACQkJcjqdbuNOp1PJyckdtg8ODtann36qyspK1y07O1s33nijKisrNXny5MubPQAA8HkerYxIUm5urubNm6fExEQlJSVp27ZtqqqqUnZ2tqQLl1i++eYb7dy5U0OGDFF8fLzb/mPGjFFgYGCHcV/hKHXIkeIwPQ0AAAYMj2MkMzNTDQ0NWr16tWpqahQfH6+SkhLFxsZKkmpqai75nSMDTakcSpHD9DQAAPBJHseIJOXk5CgnJ6fTxwoLC7vd1+FwyOFwePO0RjhKHaanAADAgMZv0wAAAKOIkV5W2snlms7GAADABcQIAAAwihi5TKx6AABweYgRAABgFDFyBbBaAgBAzxEjVxhhAgBA94gRD/z0O0c8/f4RogQAgM559aVnuLTuPuLrcDjcvrXVh74DDgCAXsfKiGGsmAAABjtiBAAAGEWMXAZvf7eG1RAAAP4/YsQL/HgeAAC9hxgxiBUSAAD4NE2vISwAAPAOKyP9AJd9AACDGTHSTxAkAIDBihgBAABGESMAAMAoYqSf4XINAGCwIUb6EUIEADAYESMAAMAoYgQAABhFjAAAAKOIEQAAYBRfB98P/fSNrI4UR5fbAQAwELAyAgAAjCJGAACAUcQIAAAwihgBAABGESP9HN/KCgAY6IgRAABgFDHiA1gdAQAMZMQIAAAwihjxEayOAAAGKmKkC/zjDwBA3yBGukGQAABw5REjAADAKGIEAAAYRYwAAACj/E1PAFJpacexlJSOY45Shxwpjis8GwAA+hYrIwAAwChiBAAAGEWMAAAAo7yKkYKCAsXFxSkwMFAJCQk6ePBgl9sWFxcrNTVVo0ePVnBwsJKSkrR//36vJwwAAAYWj2OkqKhIy5Yt08qVK1VRUaFp06YpPT1dVVVVnW5/4MABpaamqqSkROXl5Zo+fboyMjJUUVFx2ZMfjPgiNgDAQGOzLMvyZIfJkyfrtttu0+bNm11jEyZM0OzZs5Wfn9+jv3HzzTcrMzNTTz/9dKePt7a2qrW11XW/qalJ0dHRamxsVHBwsCfT9VpP/9Hv7JMwvaGzT9NcxCdqAAC+oKmpSSEhIZf899ujlZGzZ8+qvLxcaWlpbuNpaWk6fPhwj/5Ge3u7mpubFRoa2uU2+fn5CgkJcd2io6M9mSYAAPAhHsVIfX29zp8/r/DwcLfx8PBw1dbW9uhvrFu3Ti0tLZozZ06X2+Tl5amxsdF1q66u9mSaAADAh3j1pWc2m83tvmVZHcY6s3v3bjkcDr3xxhsaM2ZMl9vZ7XbZ7XZvptYreF8GAAB9x6MYCQsLk5+fX4dVkLq6ug6rJT9XVFSkhQsXas+ePbr77rs9nykAABiQPLpMExAQoISEBDmdTrdxp9Op5OTkLvfbvXu3FixYoFdffVWzZs3ybqZwYeUGADCQeHyZJjc3V/PmzVNiYqKSkpK0bds2VVVVKTs7W9KF93t888032rlzp6QLIZKVlaXnn39eU6ZMca2qDBs2TCEhIb34UnoH/9ADANC3PI6RzMxMNTQ0aPXq1aqpqVF8fLxKSkoUGxsrSaqpqXH7zpGtW7eqra1NS5Ys0ZIlS1zj8+fPV2Fh4eW/AgAA4NO8egNrTk6OcnJyOn3s54FReqW+iAMAAAwI/DYNAAAwihjxUY5SB+9vAQAMCMQIAAAwihjxcayOAAB8HTECAACMIkYAAIBRxAgAADCKGBkAeN8IAMCXESMAAMAoYuQnWGEAAKDvESP9VGmp++1SCCkAgK8iRgAAgFHECAAAMIoYAQAARhEjAADAKGJkAOFNrAAAX0SMAAAAo4gRAABgFDHyf7jEAQCAGcTIAENUAQB8DTECAACMIkYAAIBRxAgAADDK3/QE0DM//7G8lBQTswAAoPexMjIA8SZWAIAvIUYAAIBRxAgAADCKGBmguFQDAPAVxAgAADCKGBnAHKUOVkgAAP0eMQIAAIwiRgYBVkcAAP0ZMQIAAIziG1h91M+/kVXiW1kBAL6JlZFBgjezAgD6q0G/MsI/0AAAmMXKyCDDCgkAoL8hRgAAgFHEyABSWup+6w6rIwCA/oIYGcQIEgBAf0CMDHK8hwQAYNqg/zTNQObJd5FcDBJHiuMKzQYAgM6xMjLIXOp9JaySAAD6mlcxUlBQoLi4OAUGBiohIUEHDx7sdvuysjIlJCQoMDBQ1113nbZs2eLVZNE3fnrphjgBAFxpHl+mKSoq0rJly1RQUKCpU6dq69atSk9P17FjxxQTE9Nh+5MnT2rmzJlavHixXnnlFb3//vvKycnR6NGj9cADD/TKi4D3fr468tPLOF0FiSPFwWUdAECvsVmWZXmyw+TJk3Xbbbdp8+bNrrEJEyZo9uzZys/P77D9E088oX379un48eOusezsbH388cc6cuRIj56zqalJISEhamxsVHBwsCfTvaTL/T//S32EdjDo8n0ohAoADGo9/ffbo5WRs2fPqry8XE8++aTbeFpamg4fPtzpPkeOHFFaWprb2D333KPt27fr3LlzGjp0aId9Wltb1dra6rrf2Ngo6cKL6m2tLa2X3qgbbZe3+4Dwv/u7Gs/rcp9p6vqxruR5vgsAwKCL/25fat3Doxipr6/X+fPnFR4e7jYeHh6u2traTvepra3tdPu2tjbV19crMjKywz75+fl65plnOoxHR0d7Ml30Y+/rTx7v8yfPdwEA9APNzc0KCQnp8nGvPtprs9nc7luW1WHsUtt3Nn5RXl6ecnNzXffb29v13XffadSoUd0+T3/W1NSk6OhoVVdX9/qlpsGA4+c9jt3l4fh5j2N3eQbC8bMsS83NzYqKiup2O49iJCwsTH5+fh1WQerq6jqsflwUERHR6fb+/v4aNWpUp/vY7XbZ7Xa3sZEjR3oy1X4rODjYZ0+q/oDj5z2O3eXh+HmPY3d5fP34dbcicpFHH+0NCAhQQkKCnE6n27jT6VRycnKn+yQlJXXY/p133lFiYmKn7xcBAACDi8ffM5Kbm6sXX3xRO3bs0PHjx7V8+XJVVVUpOztb0oVLLFlZWa7ts7Oz9fXXXys3N1fHjx/Xjh07tH37dq1YsaL3XgUAAPBZHr9nJDMzUw0NDVq9erVqamoUHx+vkpISxcbGSpJqampUVVXl2j4uLk4lJSVavny5Nm3apKioKL3wwguD7jtG7Ha7Vq1a1eHyE3qG4+c9jt3l4fh5j2N3eQbT8fP4e0YAAAB6E79NAwAAjCJGAACAUcQIAAAwihgBAABGESMAAMAoYqSPFBQUKC4uToGBgUpISNDBgwdNT6nfczgcstlsbreIiAjT0+q3Dhw4oIyMDEVFRclms2nv3r1uj1uWJYfDoaioKA0bNkwpKSn67LPPzEy2n7nUsVuwYEGHc3HKlClmJtvP5Ofn6/bbb1dQUJDGjBmj2bNn6/PPP3fbhnOvaz05foPh/CNG+kBRUZGWLVumlStXqqKiQtOmTVN6errb97GgczfffLNqampct08//dT0lPqtlpYWTZo0SRs3buz08bVr12r9+vXauHGjPvzwQ0VERCg1NVXNzc19PNP+51LHTpLuvfdet3OxpKSkD2fYf5WVlWnJkiX64IMP5HQ61dbWprS0NLW0tLi24dzrWk+OnzQIzj8LV9wdd9xhZWdnu43ddNNN1pNPPmloRr5h1apV1qRJk0xPwydJsl5//XXX/fb2disiIsL605/+5Br78ccfrZCQEGvLli0GZth//fzYWZZlzZ8/3/rNb35jZD6+pq6uzpJklZWVWZbFueepnx8/yxoc5x8rI1fY2bNnVV5errS0NLfxtLQ0HT582NCsfMcXX3yhqKgoxcXF6aGHHtKJEydMT8knnTx5UrW1tW7nod1u15133sl52EOlpaUaM2aMxo8fr8WLF6uurs70lPqlxsZGSVJoaKgkzj1P/fz4XTTQzz9i5Aqrr6/X+fPnO/yqcXh4eIdfM4a7yZMna+fOndq/f7/++te/qra2VsnJyWpoaDA9NZ9z8VzjPPROenq6du3apXfffVfr1q3Thx9+qBkzZqi1tdX01PoVy7KUm5urX/7yl4qPj5fEueeJzo6fNDjOP49/mwbesdlsbvcty+owBnfp6emu/544caKSkpJ0/fXX6+WXX1Zubq7BmfkuzkPvZGZmuv47Pj5eiYmJio2N1VtvvaX777/f4Mz6l0cffVSffPKJDh061OExzr1L6+r4DYbzj5WRKywsLEx+fn4d/g+grq6uw/8poHsjRozQxIkT9cUXX5ieis+5+CkkzsPeERkZqdjYWM7Fn3jssce0b98+vffeexo7dqxrnHOvZ7o6fp0ZiOcfMXKFBQQEKCEhQU6n023c6XQqOTnZ0Kx8U2trq44fP67IyEjTU/E5cXFxioiIcDsPz549q7KyMs5DLzQ0NKi6uppzURdWOB599FEVFxfr3XffVVxcnNvjnHvdu9Tx68xAPP+4TNMHcnNzNW/ePCUmJiopKUnbtm1TVVWVsrOzTU+tX1uxYoUyMjIUExOjuro6Pfvss2pqatL8+fNNT61fOnPmjL788kvX/ZMnT6qyslKhoaGKiYnRsmXLtGbNGo0bN07jxo3TmjVrNHz4cM2dO9fgrPuH7o5daGioHA6HHnjgAUVGRuqrr77SU089pbCwMP32t781OOv+YcmSJXr11Vf1xhtvKCgoyLUCEhISomHDhslms3HudeNSx+/MmTOD4/wz+EmeQWXTpk1WbGysFRAQYN12221uH9tC5zIzM63IyEhr6NChVlRUlHX//fdbn332melp9VvvvfeeJanDbf78+ZZlXfiI5apVq6yIiAjLbrdbv/rVr6xPP/3U7KT7ie6O3ffff2+lpaVZo0ePtoYOHWrFxMRY8+fPt6qqqkxPu1/o7LhJsl566SXXNpx7XbvU8Rss55/NsiyrL+MHAADgp3jPCAAAMIoYAQAARhEjAADAKGIEAAAYRYwAAACjiBEAAGAUMQIAAIwiRgAAgFHECAAAMIoYAQAARhEjAADAqP8HVWIq9wE+1MgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normalize(data_socat[\"mlotst\"]), 100, density=True, facecolor='blue', alpha=0.5);\n",
    "plt.hist(normalize(np.log(data_socat[\"mlotst\"])), 100, density=True, facecolor='green', alpha=0.5);\n",
    "plt.title(\"mlotst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c90fa223-25af-4061-802a-ac8848fd0a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'chlos')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(normalize(data_socat[\"chlos\"]), 100, density=True, facecolor='blue', alpha=0.5);\n",
    "plt.hist(normalize(np.log(data_socat[\"chlos\"])), 100, density=True, facecolor='green', alpha=0.5);\n",
    "plt.title(\"chlos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4d20e19-714d-47e8-adaf-8137a3a546fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_dict in [data_socat, data_bgcargo, data_glodap_4, data_glodap_2]:\n",
    "    data_dict[\"mlotst\"] = np.log(data_dict[\"mlotst\"])\n",
    "    data_dict[\"chlos\"] = np.log(data_dict[\"chlos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb280ce-9408-41a1-af44-5d6d355240f5",
   "metadata": {},
   "source": [
    "####  Split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46f723c0-6b32-4691-97b5-ac59f6d060e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "train_valid_split = 0.833 \n",
    "# As before, have 5/6 as training and 1/6 as validation data\n",
    "random_indices = [np.arange(len(data_socat[\"tos\"]), dtype=int),\n",
    "                  np.arange(len(data_bgcargo[\"tos\"]), dtype=int),\n",
    "                  np.arange(len(data_glodap_4[\"tos\"]), dtype=int),\n",
    "                  np.arange(len(data_glodap_2[\"tos\"]), dtype=int)]\n",
    "\n",
    "for indices in random_indices:\n",
    "    random.shuffle(indices)\n",
    "\n",
    "ntrain_socat = int(len(data_socat[\"tos\"]) * train_valid_split)\n",
    "train_socat = {key: data_socat[key][random_indices[0]][:ntrain_socat]\n",
    "               for key in data_socat}\n",
    "valid_socat = {key: data_socat[key][random_indices[0]][ntrain_socat:]\n",
    "               for key in data_socat}\n",
    "\n",
    "ntrain_bgcargo = int(len(data_bgcargo[\"tos\"]) * train_valid_split)\n",
    "train_bgcargo = {key: data_bgcargo[key][random_indices[1]][:ntrain_bgcargo]\n",
    "               for key in data_bgcargo}\n",
    "valid_bgcargo = {key: data_bgcargo[key][random_indices[1]][ntrain_bgcargo:]\n",
    "               for key in data_bgcargo}\n",
    "\n",
    "ntrain_glodap_4 = int(len(data_glodap_4[\"tos\"]) * train_valid_split)\n",
    "train_glodap_4 = {key: data_glodap_4[key][random_indices[2]][:ntrain_glodap_4]\n",
    "               for key in data_glodap_4}\n",
    "valid_glodap_4 = {key: data_glodap_4[key][random_indices[2]][ntrain_glodap_4:]\n",
    "               for key in data_glodap_4}\n",
    "\n",
    "ntrain_glodap_2 = int(len(data_glodap_2[\"tos\"]) * train_valid_split)\n",
    "train_glodap_2 = {key: data_glodap_2[key][random_indices[3]][:ntrain_glodap_2]\n",
    "               for key in data_glodap_2}\n",
    "valid_glodap_2 = {key: data_glodap_2[key][random_indices[3]][ntrain_glodap_2:]\n",
    "               for key in data_glodap_2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29a6f7-dc31-47fb-8a84-0c0df423b7f0",
   "metadata": {},
   "source": [
    "#### normalize data and convert into feature and label arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e12d1f1-7feb-4ad8-90aa-b184f0cd72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_keys = [\"tos\", \"sos\", \"mlotst\", \"zos\", \"chlos\", \"siconc\", \"uas\", \"vas\",\n",
    "                \"co2\", \"mon_sin\", \"mon_cos\", \"nvector1\", \"nvector2\", \"nvector3\"]\n",
    "\n",
    "with open('../data/cmip6_base_model_train_feature_means.pkl', 'rb') as f:\n",
    "    train_feature_means = pickle.load(f)\n",
    "\n",
    "with open('../data/cmip6_base_model_train_feature_stds.pkl', 'rb') as f:\n",
    "    train_feature_stds = pickle.load(f)\n",
    "\n",
    "# normalize across the four training sets, because all four are used to train the same network\n",
    "# train_feature_means = {\n",
    "#     key: np.mean(np.concatenate([\n",
    "#         train_socat[key], train_bgcargo[key], train_glodap_4[key], train_glodap_2[key]\n",
    "#     ])) for key in feature_keys}\n",
    "\n",
    "# train_feature_stds = {\n",
    "#     key: np.std(np.concatenate([\n",
    "#         train_socat[key], train_bgcargo[key], train_glodap_4[key], train_glodap_2[key]\n",
    "#     ])) for key in feature_keys}\n",
    "\n",
    "# set up train_features, valid_features, train_labels, valid_labels as dictionaries\n",
    "train_features = {}\n",
    "valid_features = {}\n",
    "train_labels = {}\n",
    "valid_labels = {}\n",
    "# with keys socat, bgcargo, glodap_4, and glodap_2, containing the respective arrays\n",
    "for data_key, train_data in zip(\n",
    "    [\"socat\", \"bgcargo\", \"glodap_4\", \"glodap_2\"],\n",
    "    [train_socat, train_bgcargo, train_glodap_4, train_glodap_2]):\n",
    "    train_features[data_key] = np.concatenate([(\n",
    "    train_data[key][:, np.newaxis] - train_feature_means[key]\n",
    ") / train_feature_stds[key] for key in feature_keys], axis=1)\n",
    "\n",
    "for data_key, valid_data in zip(\n",
    "    [\"socat\", \"bgcargo\", \"glodap_4\", \"glodap_2\"],\n",
    "    [valid_socat, valid_bgcargo, valid_glodap_4, valid_glodap_2]):\n",
    "    valid_features[data_key] = np.concatenate([(\n",
    "    valid_data[key][:, np.newaxis] - train_feature_means[key]\n",
    ") / train_feature_stds[key] for key in feature_keys], axis=1)\n",
    "\n",
    "\n",
    "train_labels[\"socat\"] = train_socat[\"fco2\"] # maybe add [:, np.newaxis]\n",
    "train_labels[\"bgcargo\"] = train_bgcargo[\"ph\"] # maybe add [:, np.newaxis]\n",
    "train_labels[\"glodap_4\"] = np.concatenate([\n",
    "    train_glodap_4[key][:, np.newaxis] for key in [\"talkos_4\", \"dissicos_4\", \"sios_4\", \"po4os_4\"]\n",
    "], axis=1)\n",
    "train_labels[\"glodap_2\"] = np.concatenate([\n",
    "    train_glodap_2[key][:, np.newaxis] for key in [\"talkos_2\", \"dissicos_2\"]\n",
    "], axis=1)\n",
    "\n",
    "valid_labels[\"socat\"] = valid_socat[\"fco2\"] # maybe add [:, np.newaxis]\n",
    "valid_labels[\"bgcargo\"] = valid_bgcargo[\"ph\"] # maybe add [:, np.newaxis]\n",
    "valid_labels[\"glodap_4\"] = np.concatenate([\n",
    "    valid_glodap_4[key][:, np.newaxis] for key in [\"talkos_4\", \"dissicos_4\", \"sios_4\", \"po4os_4\"]\n",
    "], axis=1)\n",
    "valid_labels[\"glodap_2\"] = np.concatenate([\n",
    "    valid_glodap_2[key][:, np.newaxis] for key in [\"talkos_2\", \"dissicos_2\"]\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02edc950-fa56-43c8-a31c-2814a15b83c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional dictionaries train_TS and valid_TS that only contain T and S normalized\n",
    "# for surrogate models\n",
    "train_TS = {}\n",
    "valid_TS = {}\n",
    "\n",
    "for data_key, train_data in zip(\n",
    "    [\"socat\", \"bgcargo\"],\n",
    "    [train_socat, train_bgcargo]):\n",
    "    train_TS[data_key] = np.concatenate([\n",
    "    (train_data[key][:, np.newaxis] - sample_means[key]) / sample_stds[key]\n",
    "        for key in [\"tos\", \"sos\"]], axis=1)\n",
    "\n",
    "for data_key, valid_data in zip(\n",
    "    [\"socat\", \"bgcargo\"],\n",
    "    [valid_socat, valid_bgcargo]):\n",
    "    valid_TS[data_key] = np.concatenate([\n",
    "    (valid_data[key][:, np.newaxis] - sample_means[key]) / sample_stds[key]\n",
    "        for key in [\"tos\", \"sos\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44f00b53-1464-47ba-9dba-1d54ad8581ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10508837\n",
      "0.88679993\n",
      "0.38822964\n",
      "0.16089724\n",
      "-0.42586675\n",
      "0.87684035\n",
      "0.3899688\n",
      "0.07397248\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(train_TS[\"socat\"][:, 0]))\n",
    "print(np.std(train_TS[\"socat\"][:, 0]))\n",
    "print(np.mean(train_TS[\"socat\"][:, 1]))\n",
    "print(np.std(train_TS[\"socat\"][:, 1]))\n",
    "\n",
    "print(np.mean(train_TS[\"bgcargo\"][:, 0]))\n",
    "print(np.std(train_TS[\"bgcargo\"][:, 0]))\n",
    "print(np.mean(train_TS[\"bgcargo\"][:, 1]))\n",
    "print(np.std(train_TS[\"bgcargo\"][:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb175517-c93e-4b25-887a-a8135e215058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270138, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_TS[\"socat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5947b215-d3d9-48ea-a4a5-612ff3be86e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check shapes of matrices.\n",
      "socat\n",
      "(270138, 14)\n",
      "(54158, 14)\n",
      "(270138,)\n",
      "(54158,)\n",
      "--------\n",
      "bgcargo\n",
      "(7871, 14)\n",
      "(1578, 14)\n",
      "(7871,)\n",
      "(1578,)\n",
      "--------\n",
      "glodap_4\n",
      "(8853, 14)\n",
      "(1776, 14)\n",
      "(8853, 4)\n",
      "(1776, 4)\n",
      "--------\n",
      "glodap_2\n",
      "(3297, 14)\n",
      "(662, 14)\n",
      "(3297, 2)\n",
      "(662, 2)\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "print(\"Check shapes of matrices.\")\n",
    "for key in [\"socat\", \"bgcargo\", \"glodap_4\", \"glodap_2\"]:\n",
    "    print(key)\n",
    "    print(train_features[key].shape)\n",
    "    print(valid_features[key].shape)\n",
    "    print(train_labels[key].shape)\n",
    "    print(valid_labels[key].shape)\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1556919-ecd3-447e-bfc3-6e339472a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check normalization of features, given that it is calculated over all four data sets.\n",
      "socat\n",
      "[ 0.3310729   0.31367438 -0.11051478  0.62111851  0.23004643 -0.39209877\n",
      " -0.11175582 -0.04413324  0.32820823 -0.00463562 -0.0036619   0.42707331\n",
      " -0.1474093   0.14421784]\n",
      "[0.83236141 1.04530271 0.6885989  0.81611698 0.6466959  0.21768168\n",
      " 0.70016144 0.74074722 0.87113164 0.99659538 1.00337704 0.8440208\n",
      " 0.95779843 1.09923154]\n",
      "[ 0.33069907  0.31003188 -0.11447119  0.62024651  0.23061405 -0.39265491\n",
      " -0.11745429 -0.04665359  0.32464282 -0.00542253 -0.00822185  0.43092135\n",
      " -0.14891047  0.15014118]\n",
      "[0.83392625 1.04288861 0.68907971 0.81466962 0.6478509  0.21493923\n",
      " 0.69934181 0.74080309 0.87268448 0.99560934 1.00432624 0.84263484\n",
      " 0.95598216 1.09848608]\n",
      "--------\n",
      "bgcargo\n",
      "[-0.16728823  0.32497331  0.41016418  0.22086302  0.07938411 -0.39257543\n",
      "  0.42018827 -0.13825112  1.42441218 -0.011216    0.0710112  -0.68532769\n",
      " -0.13815271  0.00160986]\n",
      "[0.82301331 0.48057777 0.6731657  0.97036451 0.40485685 0.22700602\n",
      " 0.87248606 0.64672044 0.28815989 1.00806647 0.98923914 0.71418372\n",
      " 0.9313177  0.99066984]\n",
      "[-0.1406197   0.33302598  0.40274821  0.24144683  0.06812071 -0.39127837\n",
      "  0.3919901  -0.13145932  1.42893162  0.01269577  0.05753645 -0.65887105\n",
      " -0.15839907  0.03706255]\n",
      "[0.84110489 0.4835941  0.67349369 0.9722136  0.40293897 0.24140979\n",
      " 0.90247018 0.66259083 0.29447846 1.01631622 0.98162651 0.73170937\n",
      " 0.93696915 0.98635601]\n",
      "--------\n",
      "glodap_4\n",
      "[ 0.15747689 -0.00674844 -0.2706477   0.52548329  0.31880462 -0.36790051\n",
      " -0.07693091 -0.00705988  0.01121608  0.11594195 -0.19218231  0.432924\n",
      "  0.05401995  0.05073081]\n",
      "[0.88531641 1.50698361 0.66255395 0.8440115  0.74155947 0.2970844\n",
      " 0.65465947 0.72064207 0.87763398 0.95743329 1.01633476 0.92079279\n",
      " 0.95789625 1.04390157]\n",
      "[ 0.17438228  0.02073747 -0.2717184   0.52063219  0.30065827 -0.37246413\n",
      " -0.06782642  0.00091172 -0.00321922  0.12370287 -0.19055799  0.4238668\n",
      "  0.0693046   0.0411185 ]\n",
      "[0.88770639 1.47409954 0.64380127 0.83742023 0.73884182 0.26503344\n",
      " 0.66811979 0.72492681 0.87766812 0.94879327 1.02378984 0.91723192\n",
      " 0.95903135 1.05484235]\n",
      "--------\n",
      "glodap_2\n",
      "[ 0.32727421  0.20968763 -0.31382887  0.46531063  0.27996937 -0.36486024\n",
      " -0.14897518  0.02052465 -0.06246879  0.11255741 -0.26184496  0.47480507\n",
      " -0.23799662 -0.48824174]\n",
      "[0.84619621 1.68593209 0.63330859 0.74310676 0.69393316 0.29010926\n",
      " 0.61117445 0.75731158 0.83730384 0.96001771 0.99859757 0.83587517\n",
      " 0.87761357 1.09589871]\n",
      "[ 0.30049246  0.22669715 -0.29775988  0.43403846  0.27380567 -0.35941056\n",
      " -0.13068269 -0.03916958 -0.07398093  0.07576556 -0.22961814  0.46708756\n",
      " -0.24805198 -0.52487148]\n",
      "[0.83623543 1.66211133 0.609967   0.74653541 0.66413953 0.32715581\n",
      " 0.6321601  0.74408869 0.85123595 0.94955803 1.01976736 0.85198624\n",
      " 0.85614646 1.08084694]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "print(\"Check normalization of features, given that it is calculated over all four data sets.\")\n",
    "for key in [\"socat\", \"bgcargo\", \"glodap_4\", \"glodap_2\"]:\n",
    "    print(key)\n",
    "    print(np.mean(train_features[key], axis=0))\n",
    "    print(np.std(train_features[key], axis=0))\n",
    "    print(np.mean(valid_features[key], axis=0))\n",
    "    print(np.std(valid_features[key], axis=0))\n",
    "    print(\"--------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bfe9b4-65c5-474f-985b-6224097f65ef",
   "metadata": {},
   "source": [
    "# Define neural network and training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52d5715f-e800-456f-a86c-70d7eeff033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class flexible_MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size_part1, inner_output_size, hidden_size_part2):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\")\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size_part1, device=self.device)\n",
    "        self.linear2 = nn.Linear(hidden_size_part1, hidden_size_part1, device=self.device)\n",
    "        self.linear3 = nn.Linear(hidden_size_part1, hidden_size_part1, device=self.device)\n",
    "        self.linear4 = nn.Linear(hidden_size_part1, inner_output_size, device=self.device)\n",
    "        \n",
    "        self.linear1_socat = nn.Linear(inner_output_size + 2, hidden_size_part2, device=self.device)\n",
    "        self.linear2_socat = nn.Linear(hidden_size_part2, hidden_size_part2, device=self.device)\n",
    "        self.linear3_socat = nn.Linear(hidden_size_part2, hidden_size_part2, device=self.device)\n",
    "        self.linear4_socat = nn.Linear(hidden_size_part2, 1, device=self.device)\n",
    "\n",
    "        self.linear1_bgcargo = nn.Linear(inner_output_size + 2, hidden_size_part2, device=self.device)\n",
    "        self.linear2_bgcargo = nn.Linear(hidden_size_part2, hidden_size_part2, device=self.device)\n",
    "        self.linear3_bgcargo = nn.Linear(hidden_size_part2, hidden_size_part2, device=self.device)\n",
    "        self.linear4_bgcargo = nn.Linear(hidden_size_part2, 1, device=self.device)\n",
    "    \n",
    "    def forward(self, x, TS_data=None, mode=None):\n",
    "        \"\"\"\n",
    "        mode can be socat, bgcargo, defaults to None\n",
    "        (i.e., only the first part of the network is used,\n",
    "        for the GLODAP data sets)\n",
    "        TS_data only needs to be provided if mode is not None\n",
    "        \"\"\"\n",
    "        x = x.to(self.device)\n",
    "        x = F.elu(self.linear1(x))\n",
    "        x = F.elu(self.linear2(x))\n",
    "        x = F.elu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        if mode == \"socat\":\n",
    "            x_p1 = x[:, :2]\n",
    "            x_p2 = x[:, 2:]\n",
    "            x = torch.cat((x_p1, TS_data, x_p2), dim=-1)\n",
    "            x = F.elu(self.linear1_socat(x))\n",
    "            x = F.elu(self.linear2_socat(x))\n",
    "            x = F.elu(self.linear3_socat(x))\n",
    "            x = F.elu(self.linear4_socat(x))\n",
    "        if mode == \"bgcargo\":\n",
    "            x_p1 = x[:, :2]\n",
    "            x_p2 = x[:, 2:]\n",
    "            x = torch.cat((x_p1, TS_data, x_p2), dim=-1)\n",
    "            x = F.elu(self.linear1_bgcargo(x))\n",
    "            x = F.elu(self.linear2_bgcargo(x))\n",
    "            x = F.elu(self.linear3_bgcargo(x))\n",
    "            x = F.elu(self.linear4_bgcargo(x))\n",
    "        return x\n",
    "\n",
    "    def save(self, file_name='model.pth'):\n",
    "        model_folder_path = '../models'\n",
    "        if not os.path.exists(model_folder_path):\n",
    "            os.makedirs(model_folder_path)\n",
    "\n",
    "        file_name = os.path.join(model_folder_path, file_name)\n",
    "        torch.save(self.state_dict(), file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7c24dab-0df0-48e5-a247-814a54f80502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flexible_MLP(\n",
      "  (linear1): Linear(in_features=14, out_features=160, bias=True)\n",
      "  (linear2): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (linear3): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (linear4): Linear(in_features=160, out_features=4, bias=True)\n",
      "  (linear1_socat): Linear(in_features=6, out_features=160, bias=True)\n",
      "  (linear2_socat): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (linear3_socat): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (linear4_socat): Linear(in_features=160, out_features=1, bias=True)\n",
      "  (linear1_bgcargo): Linear(in_features=6, out_features=160, bias=True)\n",
      "  (linear2_bgcargo): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (linear3_bgcargo): Linear(in_features=160, out_features=160, bias=True)\n",
      "  (linear4_bgcargo): Linear(in_features=160, out_features=1, bias=True)\n",
      ")\n",
      "Update the base, socat and bgcargo subnets and freeze these layers\n",
      "Number of trainable parameters in the model: 54564\n"
     ]
    }
   ],
   "source": [
    "model = flexible_MLP(14, 160, 4, 160)\n",
    "print(model)\n",
    "\n",
    "print(\"Update the base, socat and bgcargo subnets and freeze these layers\")\n",
    "base_state_dict = torch.load(\"../models/CMIP6_base_model_160x3_elu_10000epo.pth\")\n",
    "socat_state_dict = torch.load(\"../models/fCO2_model_160x3_elu_10000epo.pth\")\n",
    "bgcargo_state_dict = torch.load(\"../models/pH_model_160x3_elu_10000epo.pth\")\n",
    "\n",
    "with torch.no_grad(): # not sure whether interfers with autograd\n",
    "    model.linear1.weight.copy_(base_state_dict[\"linear1.weight\"])\n",
    "    model.linear1.bias.copy_(base_state_dict[\"linear1.bias\"])\n",
    "    model.linear2.weight.copy_(base_state_dict[\"linear2.weight\"])\n",
    "    model.linear2.bias.copy_(base_state_dict[\"linear2.bias\"])\n",
    "    model.linear3.weight.copy_(base_state_dict[\"linear3.weight\"])\n",
    "    model.linear3.bias.copy_(base_state_dict[\"linear3.bias\"])\n",
    "    model.linear4.weight.copy_(base_state_dict[\"linear4.weight\"])\n",
    "    model.linear4.bias.copy_(base_state_dict[\"linear4.bias\"])\n",
    "    \n",
    "    model.linear1_socat.weight.copy_(socat_state_dict[\"linear1.weight\"])\n",
    "    model.linear1_socat.bias.copy_(socat_state_dict[\"linear1.bias\"])\n",
    "    model.linear2_socat.weight.copy_(socat_state_dict[\"linear2.weight\"])\n",
    "    model.linear2_socat.bias.copy_(socat_state_dict[\"linear2.bias\"])\n",
    "    model.linear3_socat.weight.copy_(socat_state_dict[\"linear3.weight\"])\n",
    "    model.linear3_socat.bias.copy_(socat_state_dict[\"linear3.bias\"])\n",
    "    model.linear4_socat.weight.copy_(socat_state_dict[\"linear4.weight\"])\n",
    "    model.linear4_socat.bias.copy_(socat_state_dict[\"linear4.bias\"])\n",
    "\n",
    "    model.linear1_bgcargo.weight.copy_(bgcargo_state_dict[\"linear1.weight\"])\n",
    "    model.linear1_bgcargo.bias.copy_(bgcargo_state_dict[\"linear1.bias\"])\n",
    "    model.linear2_bgcargo.weight.copy_(bgcargo_state_dict[\"linear2.weight\"])\n",
    "    model.linear2_bgcargo.bias.copy_(bgcargo_state_dict[\"linear2.bias\"])\n",
    "    model.linear3_bgcargo.weight.copy_(bgcargo_state_dict[\"linear3.weight\"])\n",
    "    model.linear3_bgcargo.bias.copy_(bgcargo_state_dict[\"linear3.bias\"])\n",
    "    model.linear4_bgcargo.weight.copy_(bgcargo_state_dict[\"linear4.weight\"])\n",
    "    model.linear4_bgcargo.bias.copy_(bgcargo_state_dict[\"linear4.bias\"])\n",
    "\n",
    "model.linear1_socat.weight.requires_grad = False\n",
    "model.linear1_socat.bias.requires_grad = False\n",
    "model.linear2_socat.weight.requires_grad = False\n",
    "model.linear2_socat.bias.requires_grad = False\n",
    "model.linear3_socat.weight.requires_grad = False\n",
    "model.linear3_socat.bias.requires_grad = False\n",
    "model.linear4_socat.weight.requires_grad = False\n",
    "model.linear4_socat.bias.requires_grad = False\n",
    "\n",
    "model.linear1_bgcargo.weight.requires_grad = False\n",
    "model.linear1_bgcargo.bias.requires_grad = False\n",
    "model.linear2_bgcargo.weight.requires_grad = False\n",
    "model.linear2_bgcargo.bias.requires_grad = False\n",
    "model.linear3_bgcargo.weight.requires_grad = False\n",
    "model.linear3_bgcargo.bias.requires_grad = False\n",
    "model.linear4_bgcargo.weight.requires_grad = False\n",
    "model.linear4_bgcargo.bias.requires_grad = False\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable parameters in the model:\", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "337e2d00-bbd4-40ec-aafc-8b962e9d26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_dataloader(features, labels, batch_size, TS=None):\n",
    "    ntrain = len(labels)\n",
    "    nbatch = ntrain // batch_size\n",
    "    indices = np.arange(ntrain, dtype=int)\n",
    "    random.shuffle(indices)\n",
    "    batch_indices = np.split(indices[:nbatch * batch_size], nbatch)\n",
    "    if TS is None:\n",
    "        batch_data = [(torch.from_numpy(np.take(features, ind, axis=0).astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "                       torch.from_numpy(np.take(labels, ind, axis=0).astype(\"float32\")).to(torch.device(\"cuda\")))\n",
    "                      for ind in batch_indices]\n",
    "    elif TS is not None:\n",
    "        batch_data = [(torch.from_numpy(np.take(features, ind, axis=0).astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "                       torch.from_numpy(np.take(labels, ind, axis=0).astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "                       torch.from_numpy(np.take(TS, ind, axis=0).astype(\"float32\")).to(torch.device(\"cuda\")))\n",
    "                      for ind in batch_indices]\n",
    "    return batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddfb7855-a4a3-4292-9b34-5d9b14586be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "\n",
    "class MSELoss_glodap_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MSELoss_glodap_2, self).__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        loss = torch.mean((input[:, :2] - target) ** 2)\n",
    "        return loss\n",
    "loss_function_glodap_2 = MSELoss_glodap_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdc82445-36c3-49f0-b1a3-98ea797ab048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(optimizer, mlp_mode):\n",
    "    \"\"\"\n",
    "    mlp_mode can be 'socat', 'bgcargo', 'glodap_4', 'glodap_2'\n",
    "    \"\"\"\n",
    "    running_loss = 0. # running loss over all batches in the epoch\n",
    "\n",
    "    if mlp_mode == 'socat' or mlp_mode == 'bgcargo':\n",
    "        training_data = training_dataloader(train_features[mlp_mode],\n",
    "                                            train_labels[mlp_mode],\n",
    "                                            batch_size, train_TS[mlp_mode])\n",
    "    \n",
    "        for batch in training_data:\n",
    "            features, labels, TS = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = torch.squeeze(model(features, TS, mlp_mode))\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            running_loss += loss.detach().cpu().item()\n",
    "    \n",
    "    elif mlp_mode == 'glodap_4' or mlp_mode == 'glodap_2':\n",
    "        training_data = training_dataloader(train_features[mlp_mode],\n",
    "                                            train_labels[mlp_mode], batch_size)\n",
    "    \n",
    "        for batch in training_data:\n",
    "            features, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = torch.squeeze(model(features))\n",
    "            \n",
    "            if mlp_mode == 'glodap_4':\n",
    "                loss = loss_function(outputs, labels)\n",
    "            elif mlp_mode == 'glodap_2':\n",
    "                loss = loss_function_glodap_2(outputs, labels)\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "                \n",
    "            running_loss += loss.detach().cpu().item()\n",
    "\n",
    "    ntrain = len(train_labels[mlp_mode])\n",
    "    nbatch = ntrain // batch_size\n",
    "\n",
    "    return running_loss / nbatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f72c7ec4-24cb-44ae-89a3-a2161e533902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gammar(reduction_factor, nepochs):                                                                                                                                                                       \n",
    "    return reduction_factor**(1 / nepochs)\n",
    "\n",
    "def train(batch_size, n_epochs, optimizer, scheduler):\n",
    "    train_stats = {\"train_loss\":[], \"valid_loss\":[], \"learn_rate\":[]}\n",
    "\n",
    "    pbar = tqdm(range(n_epochs), postfix=f'epoch 0/{n_epochs}')\n",
    "    for epoch in pbar:\n",
    "\n",
    "        mlp_mode = 'socat'\n",
    "        # if epoch % 4 == 0:\n",
    "        #     mlp_mode = 'socat'\n",
    "        # elif epoch % 4 == 1:\n",
    "        #     mlp_mode = 'bgcargo'\n",
    "        # elif epoch % 4 == 2:\n",
    "        #     mlp_mode = 'glodap_4'\n",
    "        # elif epoch % 4 == 3:\n",
    "        #     mlp_mode = 'glodap_2'\n",
    "\n",
    "        # if epoch % 2 == 0:\n",
    "        #     mlp_mode = 'glodap_4'\n",
    "        # elif epoch % 2 == 1:\n",
    "        #     mlp_mode = 'glodap_2'\n",
    "\n",
    "        # if epoch % 3 == 0:\n",
    "        #     mlp_mode = 'socat'\n",
    "        # elif epoch % 3 == 1:\n",
    "        #     mlp_mode = 'glodap_4'\n",
    "        # elif epoch % 3 == 2:\n",
    "        #     mlp_mode = 'glodap_2'\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss_epoch = train_one_epoch(optimizer, mlp_mode)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if mlp_mode == 'socat' or mlp_mode == 'bgcargo':\n",
    "                valid_outputs = torch.squeeze(model(\n",
    "                    torch.from_numpy(valid_features[mlp_mode].astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "                    torch.from_numpy(valid_TS[mlp_mode].astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "                    mlp_mode))\n",
    "                valid_loss_epoch = loss_function(\n",
    "                    valid_outputs, torch.from_numpy(valid_labels[mlp_mode]\n",
    "                                                   ).to(torch.device(\"cuda\"))\n",
    "                                            ).detach().cpu().item()\n",
    "\n",
    "            elif mlp_mode == 'glodap_4' or mlp_mode == 'glodap_2':\n",
    "                valid_outputs = torch.squeeze(model(\n",
    "                    torch.from_numpy(valid_features[mlp_mode].astype(\"float32\"))).to(torch.device(\"cuda\")))\n",
    "                if mlp_mode == 'glodap_4':\n",
    "                    valid_loss_epoch = loss_function(\n",
    "                        valid_outputs, torch.from_numpy(valid_labels[mlp_mode]\n",
    "                                                       ).to(torch.device(\"cuda\"))\n",
    "                                                ).detach().cpu().item()\n",
    "                if mlp_mode == 'glodap_2':\n",
    "                    valid_loss_epoch = loss_function_glodap_2(\n",
    "                        valid_outputs, torch.from_numpy(valid_labels[mlp_mode]\n",
    "                                                       ).to(torch.device(\"cuda\"))\n",
    "                                                ).detach().cpu().item()\n",
    "                \n",
    "        train_stats[\"train_loss\"].append(train_loss_epoch)\n",
    "        train_stats[\"valid_loss\"].append(valid_loss_epoch)\n",
    "        \n",
    "        lr = scheduler.get_last_lr()[0]\n",
    "        train_stats[\"learn_rate\"].append(lr)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        pbar.set_postfix({'epoch': f'{epoch+1}/{n_epochs}',\n",
    "                          'train_loss': f'{train_loss_epoch:.3e}',\n",
    "                          'valid_loss': f'{valid_loss_epoch:.3e}',\n",
    "                          'learn_rate': f'{lr:.3e}',\n",
    "                          'mode': mlp_mode},\n",
    "                        )\n",
    "\n",
    "    return train_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa4eb1-4ba1-42d2-9c36-4493d67bee00",
   "metadata": {},
   "source": [
    "# Test zero-shot inference with pretrained base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f0e408-8e30-4f52-a23a-d9ff844e15d4",
   "metadata": {},
   "source": [
    "Mostly to test whether the order of magnitude of the output fits.\n",
    "Mediocre performance should be expected, given that the input features\n",
    "are normalized differently to the model-based feature normalization\n",
    "during the CMIP6 base model training\n",
    "\n",
    "**On socat validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dacad96-9a82-4cdb-afba-665151e5c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(x, y):\n",
    "    return np.sum((x - y)**2, axis=0) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "327ce1b1-1158-4b41-8d24-633e1a1b066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_output_zero_shot = model(\n",
    "        torch.from_numpy(valid_features['socat'].astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "        torch.from_numpy(valid_TS['socat'].astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "        'socat').detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1537cdaa-4494-4be4-903e-eaf5cff05d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  49.52545738812077\n",
      "Maximum absolute deviation:  3943.7754\n",
      "99.9th percentile of absolute deviation (1000 val's larger):  287.76951257324373\n",
      "99.99th percentile of absolute deviation (100 val's larger):  545.3872545286408\n",
      "99.999th percentile of absolute deviation (10 val's larger):  3884.9338630125617\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(MSE(valid_labels['socat'], model_output_zero_shot)))\n",
    "print(\"Maximum absolute deviation: \", np.max(np.abs(model_output_zero_shot-valid_labels['socat'])))\n",
    "print(\"99.9th percentile of absolute deviation (1000 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_zero_shot-valid_labels['socat']), q=99.9))\n",
    "print(\"99.99th percentile of absolute deviation (100 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_zero_shot-valid_labels['socat']), q=99.99))\n",
    "print(\"99.999th percentile of absolute deviation (10 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_zero_shot-valid_labels['socat']), q=99.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de2c40d5-be88-495a-8016-e29f5b2766bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[407.1605  443.2639  396.05356 437.08728 259.41373 365.39157 407.44818\n",
      " 382.3938  346.84412 406.29935]\n",
      "[576.479   390.8506  393.4201  454.84305 136.84183 340.29868 376.43567\n",
      " 351.80457 380.99127 380.20386]\n"
     ]
    }
   ],
   "source": [
    "print(model_output_zero_shot[:10])\n",
    "print(valid_labels['socat'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7078322-670f-42b7-a2ef-60d1d11f5c72",
   "metadata": {},
   "source": [
    "**On bgcargo data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6501ac8b-07cb-4bb1-9372-d4f6a3ddc700",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_output_zero_shot = model(\n",
    "        torch.from_numpy(valid_features['bgcargo'].astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "        torch.from_numpy(valid_TS['bgcargo'].astype(\"float32\")).to(torch.device(\"cuda\")),\n",
    "        'bgcargo').detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5bf40ac-a7db-4d55-9658-24308c3675b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.037845265331573764\n",
      "Maximum absolute deviation:  0.2852664\n",
      "99.9th percentile of absolute deviation (1000 val's larger):  0.22117809343338324\n",
      "99.99th percentile of absolute deviation (100 val's larger):  0.27639395461081306\n",
      "99.999th percentile of absolute deviation (10 val's larger):  0.2843791549062615\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: \", np.sqrt(MSE(valid_labels['bgcargo'], model_output_zero_shot)))\n",
    "print(\"Maximum absolute deviation: \", np.max(np.abs(model_output_zero_shot-valid_labels['bgcargo'])))\n",
    "print(\"99.9th percentile of absolute deviation (1000 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_zero_shot-valid_labels['bgcargo']), q=99.9))\n",
    "print(\"99.99th percentile of absolute deviation (100 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_zero_shot-valid_labels['bgcargo']), q=99.99))\n",
    "print(\"99.999th percentile of absolute deviation (10 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_zero_shot-valid_labels['bgcargo']), q=99.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6022915-2c8e-47a1-a931-772b4591c743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.058367 8.030563 8.051839 8.047309 8.001977 8.02157  8.010197 8.021605\n",
      " 8.02684  8.035014]\n",
      "[8.045084 8.052956 8.052579 8.127767 8.002916 8.004313 8.097033 8.007573\n",
      " 8.072128 8.059124]\n"
     ]
    }
   ],
   "source": [
    "print(model_output_zero_shot[:10])\n",
    "print(valid_labels['bgcargo'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776867fa-e126-4b61-a089-28b47be17ab5",
   "metadata": {},
   "source": [
    "**On glodap_4 data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "380430fc-0d97-485a-936a-a5f2af3d5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_means_array = np.concatenate(\n",
    "    [np.array(sample_means[key])[np.newaxis]\n",
    "     for key in ['talkos', 'dissicos', 'sios', 'po4os']], axis=0)\n",
    "sample_stds_array = np.concatenate(\n",
    "    [np.array(sample_stds[key])[np.newaxis]\n",
    "     for key in ['talkos', 'dissicos', 'sios', 'po4os']], axis=0)\n",
    "\n",
    "def denormalize(array, mode):\n",
    "    if mode == 'glodap_4':\n",
    "        return array * sample_stds_array + sample_means_array\n",
    "    elif mode == 'glodap_2':\n",
    "        return array * sample_stds_array[:2] + sample_means_array[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f3333f2-b1c6-48ef-b7a4-7072be9660ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_output_zero_shot = model(\n",
    "        torch.from_numpy(valid_features['glodap_4'].astype(\"float32\")).to(torch.device(\"cuda\"))).detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c188fee-f12f-43f2-9f51-0818bdcfaef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  [126.62722705 114.52967997  15.02838226   0.2515668 ]\n",
      "Maximum absolute deviation:  [1124.19378317 1028.12749456   73.24865607    1.55872371]\n",
      "99.9th percentile of absolute deviation (1000 val's larger):  [1009.59302849  937.02611229   68.60630453    1.43207095]\n",
      "99.99th percentile of absolute deviation (100 val's larger):  [1122.16800022 1027.12301468   72.70113177    1.54956495]\n",
      "99.999th percentile of absolute deviation (10 val's larger):  [1123.99120487 1028.02704657   73.19390364    1.55780784]\n"
     ]
    }
   ],
   "source": [
    "valid_labels_den = denormalize(valid_labels['glodap_4'] * 1e6, mode=\"glodap_4\")\n",
    "model_output_den = denormalize(model_output_zero_shot * 1e6, mode=\"glodap_4\")\n",
    "\n",
    "print(\"RMSE: \", np.sqrt(MSE(valid_labels_den, model_output_den)))\n",
    "print(\"Maximum absolute deviation: \", np.max(np.abs(model_output_den-valid_labels_den), axis=0))\n",
    "print(\"99.9th percentile of absolute deviation (1000 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_den-valid_labels_den), q=99.9, axis=0))\n",
    "print(\"99.99th percentile of absolute deviation (100 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_den-valid_labels_den), q=99.99, axis=0))\n",
    "print(\"99.999th percentile of absolute deviation (10 val's larger): \",\n",
    "      np.percentile(np.abs(model_output_den-valid_labels_den), q=99.999, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8919d11-0169-49a8-8086-dfb31ac4609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.23735301e+03 1.91318370e+03 2.04176155e-01 3.11383323e-01]\n",
      " [2.23008402e+03 2.04454534e+03 7.71943942e+00 3.75820524e-01]\n",
      " [1.86242671e+03 1.78213851e+03 9.28035386e+00 5.39205140e-01]\n",
      " [2.33585014e+03 1.99831239e+03 3.57926437e-01 2.33965906e-01]\n",
      " [2.04701333e+03 1.86544010e+03 1.99177335e+00 1.48818282e-01]\n",
      " [2.33363719e+03 2.00703735e+03 1.38180316e+00 4.28470852e-02]\n",
      " [2.25748142e+03 1.94424458e+03 6.83546437e-02 1.58000156e-01]\n",
      " [1.69120541e+03 1.62212363e+03 9.42533805e+00 5.40125887e-01]\n",
      " [2.20542384e+03 2.05799018e+03 7.21454744e+01 1.17687629e+00]\n",
      " [2.21858560e+03 1.94336688e+03 1.19687120e+00 1.74443122e-01]]\n",
      "[[2.22579986e+03 1.89510000e+03 1.13299534e+00 3.04500957e-02]\n",
      " [2.30899652e+03 2.14166988e+03 4.23249627e+00 5.84999848e-01]\n",
      " [1.92655194e+03 1.84019794e+03 2.60405842e+00 5.39999937e-01]\n",
      " [2.40599982e+03 2.04880001e+03 2.37594315e-01 2.59999983e-01]\n",
      " [2.15943334e+03 1.92696670e+03 3.22333884e+00 2.76666632e-01]\n",
      " [2.37285012e+03 2.05594998e+03 1.05000099e+00 1.04999967e-01]\n",
      " [2.32779993e+03 1.97050000e+03 5.70000563e-01 9.99983268e-03]\n",
      " [2.00879983e+03 1.87200006e+03 3.23000219e+00 6.59999976e-01]\n",
      " [2.28399983e+03 2.10989988e+03 1.69950009e+01 1.11150004e+00]\n",
      " [2.32513311e+03 2.03366673e+03 2.30399590e+00 3.93333314e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(denormalize(model_output_zero_shot[:10], mode=\"glodap_4\") * 1e6)\n",
    "print(denormalize(valid_labels['glodap_4'][:10], mode=\"glodap_4\") * 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f93de-42b2-42d7-8c9f-6ca25328ccd1",
   "metadata": {},
   "source": [
    "**On glodap_2 data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa86dca6-2f42-4d31-95ae-93747654f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    model_output_zero_shot = model(\n",
    "        torch.from_numpy(valid_features['glodap_2'].astype(\"float32\")).to(torch.device(\"cuda\"))).detach().cpu().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df3bac28-3d51-4f6d-9aab-6b4a5fab2e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2207.19300265 2099.22985625]\n",
      " [2359.33010103 2022.56361374]\n",
      " [2199.57764864 2051.43920655]\n",
      " [2291.78092039 1975.34273076]\n",
      " [2381.73438929 2061.84124727]\n",
      " [2360.92664651 2020.50953082]\n",
      " [2197.17653288 1883.696759  ]\n",
      " [2359.53864234 2022.959123  ]\n",
      " [2199.48788296 2078.12677736]\n",
      " [2291.65755065 2044.08711834]]\n",
      "[[2304.69988259 2198.20000348]\n",
      " [2394.89988448 2044.10010223]\n",
      " [2289.30000145 2089.86668441]\n",
      " [2383.66112518 2058.85432181]\n",
      " [2428.14969745 2091.44993048]\n",
      " [2378.79987578 2025.60005671]\n",
      " [2243.80000381 1922.09997749]\n",
      " [2403.99982206 2053.49991282]\n",
      " [2285.60007939 2153.49999266]\n",
      " [2330.49984971 2069.50006017]]\n"
     ]
    }
   ],
   "source": [
    "print(denormalize(model_output_zero_shot[:10, :2], mode=\"glodap_2\") * 1e6)\n",
    "print(denormalize(valid_labels['glodap_2'][:10], mode=\"glodap_2\") * 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efab4db-ae79-40d9-9506-9f5619bc4c94",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd43f35b-ee33-4082-bca5-3a58ab5097ab",
   "metadata": {},
   "source": [
    "#### First fully retrain the base network (no transfer learning case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db266be0-9bdc-42d8-8367-e97dff5838a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 10000/10000 [1:01:09<00:00,  2.72it/s, epoch=10000/10000, train_loss=1.079e+02, valid_loss=1.251e+03, learn_rate=1.000e-05, mode=socat]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "n_epochs = 10_000\n",
    "\n",
    "base_learning_rate = 1e-3\n",
    "gamma = calc_gammar(0.1, 5000)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=base_learning_rate)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                       lr=base_learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                 gamma=gamma)\n",
    "\n",
    "train_stats = train(batch_size, n_epochs, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a4eebe-d207-4685-b486-d67f5faaebb8",
   "metadata": {},
   "source": [
    "#### Freeze all layers of the base model despite the last linear projection layer and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3982952b-f773-465c-9c25-b66016c06506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters in the model: 644\n"
     ]
    }
   ],
   "source": [
    "model.linear1.weight.requires_grad = False\n",
    "model.linear1.bias.requires_grad = False\n",
    "model.linear2.weight.requires_grad = False\n",
    "model.linear2.bias.requires_grad = False\n",
    "model.linear3.weight.requires_grad = False\n",
    "model.linear3.bias.requires_grad = False\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of trainable parameters in the model:\", pytorch_total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "e5cb241a-52b1-4cb3-a506-52ecd9c4712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1000/1000 [01:46<00:00,  9.37it/s, epoch=1000/1000, train_loss=8.926e+02, valid_loss=1.822e+03, learn_rate=1.005e-05, mode=socat]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "n_epochs = 1_000\n",
    "\n",
    "base_learning_rate = 1e-3\n",
    "gamma = calc_gammar(0.1, 500)\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=base_learning_rate)\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                       lr=base_learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer,\n",
    "                                                 gamma=gamma)\n",
    "\n",
    "train_stats = train(batch_size, n_epochs, optimizer, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
